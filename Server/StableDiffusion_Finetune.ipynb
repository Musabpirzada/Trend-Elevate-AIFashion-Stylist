{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0yDLXZfWSje"
      },
      "source": [
        "#1ST try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r7noiti4SFY0",
        "outputId": "b22c27c4-d81e-44c8-c4a5-e4af9a6e1356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 63899, done.\u001b[K\n",
            "remote: Counting objects: 100% (413/413), done.\u001b[K\n",
            "remote: Compressing objects: 100% (208/208), done.\u001b[K\n",
            "remote: Total 63899 (delta 263), reused 290 (delta 177), pack-reused 63486\u001b[K\n",
            "Receiving objects: 100% (63899/63899), 47.36 MiB | 9.76 MiB/s, done.\n",
            "Resolving deltas: 100% (46763/46763), done.\n",
            "Processing ./diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (0.23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (0.4.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.29.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0.dev0) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.2->diffusers==0.29.0.dev0) (4.12.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.29.0.dev0) (3.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.29.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.29.0.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.29.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.29.0.dev0) (2024.6.2)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.29.0.dev0-py3-none-any.whl size=2178831 sha256=8bef9138b967f5b03f7a64837e59e3a65cefcad7998ce4646e2eaa2545028825\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4v4ec5iy/wheels/95/c5/3b/e1b4269f8a2584de57e75f949a185b48fc4144e9a91fc9965a\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.29.0.dev0\n",
            "Collecting accelerate>=0.16.0 (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 1))\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 2)) (0.18.0+cu121)\n",
            "Collecting torchvision (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 2))\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (4.41.2)\n",
            "Collecting datasets>=2.19.1 (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading datasets-2.19.2-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.1/542.1 kB\u001b[0m \u001b[31m55.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ftfy (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 5))\n",
            "  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (2.15.2)\n",
            "Collecting tensorboard (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 6))\n",
            "  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 7)) (3.1.4)\n",
            "Collecting peft==0.7.0 (from -r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading peft-0.7.0-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (4.66.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (0.4.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (0.23.2)\n",
            "Collecting torch>=1.13.0 (from peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r /content/diffusers/examples/text_to_image/requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Collecting triton==2.3.1 (from torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (0.19.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (2.0.3)\n",
            "Collecting requests (from transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3))\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (3.9.5)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r /content/diffusers/examples/text_to_image/requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/diffusers/examples/text_to_image/requirements.txt (line 6)) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r /content/diffusers/examples/text_to_image/requirements.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 3)) (2024.6.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.19.1->-r /content/diffusers/examples/text_to_image/requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.0->-r /content/diffusers/examples/text_to_image/requirements.txt (line 8)) (1.3.0)\n",
            "Installing collected packages: xxhash, triton, requests, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, dill, tensorboard, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, torch, datasets, torchvision, accelerate, peft\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.0\n",
            "    Uninstalling triton-2.3.0:\n",
            "      Successfully uninstalled triton-2.3.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.2\n",
            "    Uninstalling tensorboard-2.15.2:\n",
            "      Successfully uninstalled tensorboard-2.15.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.0+cu121\n",
            "    Uninstalling torch-2.3.0+cu121:\n",
            "      Successfully uninstalled torch-2.3.0+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.0+cu121\n",
            "    Uninstalling torchvision-0.18.0+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.0+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.17.0 which is incompatible.\n",
            "torchaudio 2.3.0+cu121 requires torch==2.3.0, but you have torch 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.31.0 datasets-2.19.2 dill-0.3.8 ftfy-6.2.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 peft-0.7.0 requests-2.32.3 tensorboard-2.17.0 torch-2.3.1 torchvision-0.18.1 triton-2.3.1 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "!cd /content/\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "!pip install ./diffusers\n",
        "!pip install -U -r /content/diffusers/examples/text_to_image/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhGITN4bSFaY",
        "outputId": "a1454b9d-5103-4453-d8da-8605f997d16e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ],
      "source": [
        "# !accelerate config default --mixed_precision fp16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ij7_u96-SFcu"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import diffusers\n",
        "\n",
        "os.environ['MODEL_NAME'] = f'CompVis/stable-diffusion-v1-4'\n",
        "os.environ['DATASET_NAME'] = f'SSTalha/Fashion_Dataset'\n",
        "os.environ['OUTPUT_DIR'] = f'Stable-Diffusion-Fashion'\n",
        "os.environ['HUB_MODEL_INFO'] = f'SSTalha/Stable-diffusion-Fashion'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "58412283b6744e699176ef1dc3dab571",
            "1029fe4c8a124a29b04c3807a00a635b",
            "5cec24f33a694d4699c3f631a8290624",
            "e10ef5e0a2a44636b2aadbb7d73f5e32",
            "9a8c4b7bf55249fab7eff6027e9f656e",
            "efc531666c5c4a9fa75c5ade50415248",
            "18cc15c5bd594449854efbfe85ef2dcf",
            "726af3feb27a42429613eff0580f68a7",
            "43dc950c29c7440692bcdfa744eee9cf",
            "1d7b168372fc4422bdf1c1b5a16a03ff",
            "302fcdbd038243c6a90ec7a8b94950fe",
            "2cbbcfebd52e4c3b8f41ba0a1297943e",
            "961441061dcb4777a764e2c5ba471c24",
            "643fbc78a3d2431685d577cfd7f5490b"
          ]
        },
        "id": "BW9qgWH_y9OR",
        "outputId": "9a1d8d16-a65d-42f9-de3b-1180f15bc1d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58412283b6744e699176ef1dc3dab571",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4pF8qAwoSFgp",
        "outputId": "3b6a99f4-289e-463f-98cf-1dc48cd444d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
            "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
            "2024-06-12 10:09:51.456505: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-06-12 10:09:51.456553: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-06-12 10:09:51.457926: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-06-12 10:09:51.465277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-06-12 10:09:53.255956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:399: UserWarning: `log_with=wandb` was passed but no supported trackers are currently installed.\n",
            "  warnings.warn(f\"`log_with={log_with}` was passed but no supported trackers are currently installed.\")\n",
            "06/12/2024 10:09:55 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: no\n",
            "\n",
            "{'sample_max_value', 'timestep_spacing', 'prediction_type', 'thresholding', 'variance_type', 'rescale_betas_zero_snr', 'clip_sample_range', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "{'time_embedding_act_fn', 'time_cond_proj_dim', 'mid_block_only_cross_attention', 'reverse_transformer_layers_per_block', 'attention_type', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'transformer_layers_per_block', 'dropout', 'class_embed_type', 'encoder_hid_dim_type', 'class_embeddings_concat', 'dual_cross_attention', 'addition_time_embed_dim', 'time_embedding_type', 'cross_attention_norm', 'upcast_attention', 'conv_out_kernel', 'num_class_embeds', 'addition_embed_type', 'resnet_out_scale_factor', 'timestep_post_act', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'resnet_skip_time_act', 'time_embedding_dim', 'num_attention_heads', 'mid_block_type', 'only_cross_attention', 'resnet_time_scale_shift', 'use_linear_projection'} was not found in config. Values will be initialized to default values.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "06/12/2024 10:10:09 - INFO - __main__ - ***** Running training *****\n",
            "06/12/2024 10:10:09 - INFO - __main__ -   Num examples = 200\n",
            "06/12/2024 10:10:09 - INFO - __main__ -   Num Epochs = 8\n",
            "06/12/2024 10:10:09 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "06/12/2024 10:10:09 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "06/12/2024 10:10:09 - INFO - __main__ -   Gradient Accumulation steps = 4\n",
            "06/12/2024 10:10:09 - INFO - __main__ -   Total optimization steps = 400\n",
            "Steps:   0% 0/400 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "Steps:  12% 50/400 [03:23<24:19,  4.17s/it, lr=9.62e-5, step_loss=0.215]  \n",
            "model_index.json: 100% 541/541 [00:00<00:00, 4.25MB/s]\n",
            "\n",
            "Fetching 14 files:   0% 0/14 [00:00<?, ?it/s]\u001b[A\n",
            "\n",
            "(…)ature_extractor/preprocessor_config.json: 100% 342/342 [00:00<00:00, 2.92MB/s]\n",
            "\n",
            "Fetching 14 files:   7% 1/14 [00:00<00:01,  9.10it/s]\u001b[A\n",
            "\n",
            "safety_checker/config.json:   0% 0.00/4.56k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "safety_checker/config.json: 100% 4.56k/4.56k [00:00<00:00, 5.24MB/s]\n",
            "(…)kpoints/scheduler_config-checkpoint.json: 100% 209/209 [00:00<00:00, 700kB/s]\n",
            "\n",
            "\n",
            "model.safetensors:   0% 0.00/1.22G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   1% 10.5M/1.22G [00:00<00:13, 92.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   3% 41.9M/1.22G [00:00<00:06, 194MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   6% 73.4M/1.22G [00:00<00:04, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:   9% 105M/1.22G [00:00<00:04, 248MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  11% 136M/1.22G [00:00<00:04, 248MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  14% 168M/1.22G [00:00<00:04, 245MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  16% 199M/1.22G [00:00<00:04, 247MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  19% 231M/1.22G [00:04<00:35, 27.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  22% 262M/1.22G [00:04<00:24, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  24% 294M/1.22G [00:04<00:17, 53.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  27% 325M/1.22G [00:07<00:37, 23.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  28% 346M/1.22G [00:07<00:30, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  30% 367M/1.22G [00:07<00:23, 35.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  33% 398M/1.22G [00:07<00:16, 50.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  35% 430M/1.22G [00:07<00:11, 68.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  37% 451M/1.22G [00:09<00:22, 33.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  39% 472M/1.22G [00:09<00:17, 42.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  41% 503M/1.22G [00:09<00:12, 58.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  44% 535M/1.22G [00:09<00:08, 77.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  46% 556M/1.22G [00:10<00:07, 87.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  47% 577M/1.22G [00:10<00:06, 94.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  49% 598M/1.22G [00:10<00:05, 107MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  51% 619M/1.22G [00:10<00:04, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  53% 640M/1.22G [00:10<00:04, 132MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  54% 661M/1.22G [00:10<00:03, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  56% 682M/1.22G [00:10<00:03, 155MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  58% 703M/1.22G [00:10<00:03, 160MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  60% 724M/1.22G [00:11<00:02, 169MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  61% 744M/1.22G [00:11<00:02, 176MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  63% 765M/1.22G [00:11<00:02, 179MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  66% 797M/1.22G [00:11<00:02, 203MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  68% 828M/1.22G [00:11<00:01, 213MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  71% 860M/1.22G [00:11<00:01, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  73% 891M/1.22G [00:11<00:01, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  76% 923M/1.22G [00:11<00:01, 229MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  78% 954M/1.22G [00:12<00:01, 218MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  81% 986M/1.22G [00:12<00:01, 219MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  84% 1.02G/1.22G [00:12<00:00, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  86% 1.05G/1.22G [00:12<00:00, 237MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  89% 1.08G/1.22G [00:12<00:00, 230MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  91% 1.11G/1.22G [00:12<00:00, 236MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  94% 1.14G/1.22G [00:12<00:00, 231MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors:  97% 1.17G/1.22G [00:14<00:00, 64.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model.safetensors: 100% 1.22G/1.22G [00:14<00:00, 84.6MB/s]\n",
            "\n",
            "Fetching 14 files: 100% 14/14 [00:14<00:00,  1.04s/it]\n",
            "{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:03,  1.85it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  4.56it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  6.84it/s]\n",
            "06/12/2024 10:13:48 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Steps:  25% 100/400 [07:39<20:53,  4.18s/it, lr=8.54e-5, step_loss=0.00301]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.62it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  5.37it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.14it/s]\n",
            "06/12/2024 10:17:49 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Steps:  38% 150/400 [11:39<17:14,  4.14s/it, lr=6.91e-5, step_loss=0.0382] {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:01,  3.14it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  5.73it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.81it/s]\n",
            "06/12/2024 10:21:49 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Steps:  50% 200/400 [15:36<13:48,  4.14s/it, lr=5.04e-5, step_loss=0.0728]06/12/2024 10:25:45 - INFO - accelerate.accelerator - Saving current state to Stable-Diffusion-Fashion/checkpoint-200\n",
            "06/12/2024 10:27:41 - INFO - accelerate.checkpointing - Model weights saved in Stable-Diffusion-Fashion/checkpoint-200/model.safetensors\n",
            "06/12/2024 10:27:41 - INFO - accelerate.checkpointing - Optimizer state saved in Stable-Diffusion-Fashion/checkpoint-200/optimizer.bin\n",
            "06/12/2024 10:27:41 - INFO - accelerate.checkpointing - Scheduler state saved in Stable-Diffusion-Fashion/checkpoint-200/scheduler.bin\n",
            "06/12/2024 10:27:41 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in Stable-Diffusion-Fashion/checkpoint-200/sampler.bin\n",
            "06/12/2024 10:27:41 - INFO - accelerate.checkpointing - Random states saved in Stable-Diffusion-Fashion/checkpoint-200/random_states_0.pkl\n",
            "Model weights saved in Stable-Diffusion-Fashion/checkpoint-200/pytorch_lora_weights.safetensors\n",
            "06/12/2024 10:27:41 - INFO - __main__ - Saved state to Stable-Diffusion-Fashion/checkpoint-200\n",
            "Steps:  50% 200/400 [17:32<13:48,  4.14s/it, lr=5e-5, step_loss=0.292]    {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:03,  1.91it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:01<00:00,  4.01it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  6.18it/s]\n",
            "06/12/2024 10:27:43 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Steps:  62% 250/400 [21:32<10:28,  4.19s/it, lr=3.09e-5, step_loss=0.00148]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.33it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  29% 2/7 [00:00<00:01,  4.05it/s]\u001b[A{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:01<00:00,  4.08it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  6.42it/s]\n",
            "06/12/2024 10:31:42 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:  75% 300/400 [25:29<06:56,  4.16s/it, lr=1.46e-5, step_loss=0.0034]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:01,  3.12it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  5.69it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.78it/s]\n",
            "06/12/2024 10:35:39 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n",
            "Steps:  88% 350/400 [29:25<03:27,  4.16s/it, lr=3.81e-6, step_loss=0.00889]{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:01,  3.19it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  5.77it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00,  8.91it/s]\n",
            "06/12/2024 10:39:36 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Steps: 100% 400/400 [33:22<00:00,  4.15s/it, lr=1.54e-9, step_loss=0.00774]06/12/2024 10:43:32 - INFO - accelerate.accelerator - Saving current state to Stable-Diffusion-Fashion/checkpoint-400\n",
            "06/12/2024 10:46:09 - INFO - accelerate.checkpointing - Model weights saved in Stable-Diffusion-Fashion/checkpoint-400/model.safetensors\n",
            "06/12/2024 10:46:09 - INFO - accelerate.checkpointing - Optimizer state saved in Stable-Diffusion-Fashion/checkpoint-400/optimizer.bin\n",
            "06/12/2024 10:46:09 - INFO - accelerate.checkpointing - Scheduler state saved in Stable-Diffusion-Fashion/checkpoint-400/scheduler.bin\n",
            "06/12/2024 10:46:09 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in Stable-Diffusion-Fashion/checkpoint-400/sampler.bin\n",
            "06/12/2024 10:46:09 - INFO - accelerate.checkpointing - Random states saved in Stable-Diffusion-Fashion/checkpoint-400/random_states_0.pkl\n",
            "Model weights saved in Stable-Diffusion-Fashion/checkpoint-400/pytorch_lora_weights.safetensors\n",
            "06/12/2024 10:46:09 - INFO - __main__ - Saved state to Stable-Diffusion-Fashion/checkpoint-400\n",
            "Steps: 100% 400/400 [35:59<00:00,  4.15s/it, lr=0, step_loss=0.00432]      {'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:02,  2.21it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:01<00:00,  4.02it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  6.14it/s]\n",
            "06/12/2024 10:46:10 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "Model weights saved in Stable-Diffusion-Fashion/pytorch_lora_weights.safetensors\n",
            "{'requires_safety_checker', 'image_encoder'} was not found in config. Values will be initialized to default values.\n",
            "\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]\u001b[ALoaded text_encoder as CLIPTextModel from `text_encoder` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  14% 1/7 [00:00<00:01,  3.61it/s]\u001b[ALoaded tokenizer as CLIPTokenizer from `tokenizer` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'prediction_type', 'timestep_spacing'} was not found in config. Values will be initialized to default values.\n",
            "Loaded scheduler as PNDMScheduler from `scheduler` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded safety_checker as StableDiffusionSafetyChecker from `safety_checker` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...:  57% 4/7 [00:00<00:00,  6.18it/s]\u001b[A{'norm_num_groups', 'force_upcast', 'latents_mean', 'latents_std'} was not found in config. Values will be initialized to default values.\n",
            "Loaded vae as AutoencoderKL from `vae` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "Loaded feature_extractor as CLIPImageProcessor from `feature_extractor` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "{'time_embedding_act_fn', 'time_cond_proj_dim', 'mid_block_only_cross_attention', 'reverse_transformer_layers_per_block', 'attention_type', 'conv_in_kernel', 'projection_class_embeddings_input_dim', 'transformer_layers_per_block', 'dropout', 'class_embed_type', 'encoder_hid_dim_type', 'class_embeddings_concat', 'dual_cross_attention', 'addition_time_embed_dim', 'time_embedding_type', 'cross_attention_norm', 'upcast_attention', 'conv_out_kernel', 'num_class_embeds', 'addition_embed_type', 'resnet_out_scale_factor', 'timestep_post_act', 'addition_embed_type_num_heads', 'encoder_hid_dim', 'resnet_skip_time_act', 'time_embedding_dim', 'num_attention_heads', 'mid_block_type', 'only_cross_attention', 'resnet_time_scale_shift', 'use_linear_projection'} was not found in config. Values will be initialized to default values.\n",
            "Loaded unet as UNet2DConditionModel from `unet` subfolder of CompVis/stable-diffusion-v1-4.\n",
            "\n",
            "Loading pipeline components...: 100% 7/7 [00:01<00:00,  3.99it/s]\n",
            "Loading unet.\n",
            "06/12/2024 10:46:42 - INFO - __main__ - Running validation... \n",
            " Generating 4 images with prompt: A man in black jacket.\n",
            "\n",
            "model.safetensors:   0% 0.00/3.44G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "optimizer.bin:   0% 0.00/6.59M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0% 0.00/3.23M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 11 LFS files:   0% 0/11 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "random_states_0.pkl:   0% 0.00/14.4k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin:   0% 0.00/1.00k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.bin:  36% 2.34M/6.59M [00:00<00:00, 23.4MB/s]\u001b[A\u001b[A\n",
            "scheduler.bin: 100% 1.00k/1.00k [00:00<00:00, 10.4kB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.safetensors:  39% 1.26M/3.23M [00:00<00:00, 12.2MB/s]\u001b[A\u001b[A\u001b[A\n",
            "random_states_0.pkl: 100% 14.4k/14.4k [00:00<00:00, 68.6kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100% 3.23M/3.23M [00:00<00:00, 7.96MB/s]\n",
            "optimizer.bin: 100% 6.59M/6.59M [00:00<00:00, 15.9MB/s]\n",
            "\n",
            "\n",
            "optimizer.bin:   0% 0.00/6.59M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 3.85M/3.44G [00:00<01:30, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   0% 16.0M/3.44G [00:00<01:42, 33.5MB/s]\u001b[A\n",
            "\n",
            "optimizer.bin:  55% 3.64M/6.59M [00:00<00:00, 27.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 8.67M/3.44G [00:00<01:17, 44.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0% 0.00/3.23M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   1% 23.6M/3.44G [00:00<01:16, 44.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "random_states_0.pkl:   0% 0.00/14.4k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   1% 29.3M/3.44G [00:00<01:11, 47.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   0% 14.8M/3.44G [00:00<01:16, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "random_states_0.pkl: 100% 14.4k/14.4k [00:00<00:00, 101kB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1% 19.3M/3.44G [00:00<01:46, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin:   0% 0.00/1.00k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   1% 34.6M/3.44G [00:00<01:42, 33.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.bin: 100% 1.00k/1.00k [00:00<00:00, 7.97kB/s]\n",
            "optimizer.bin: 100% 6.59M/6.59M [00:00<00:00, 10.5MB/s]\n",
            "\n",
            "pytorch_lora_weights.safetensors: 100% 3.23M/3.23M [00:00<00:00, 6.12MB/s]\n",
            "\n",
            "\n",
            "pytorch_lora_weights.safetensors:   0% 0.00/3.23M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "pytorch_lora_weights.safetensors: 100% 3.23M/3.23M [00:00<00:00, 10.2MB/s]\n",
            "\n",
            "model.safetensors:   2% 58.8M/3.44G [00:01<01:22, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1% 32.0M/3.44G [00:01<03:26, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   1% 46.0M/3.44G [00:01<01:46, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   2% 64.9M/3.44G [00:01<01:56, 28.9MB/s]\u001b[A\n",
            "model.safetensors:   2% 78.9M/3.44G [00:02<01:14, 45.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 52.7M/3.44G [00:01<01:49, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 62.2M/3.44G [00:01<01:23, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   2% 86.0M/3.44G [00:02<01:24, 39.7MB/s]\u001b[A\n",
            "model.safetensors:   3% 96.0M/3.44G [00:02<01:20, 41.4MB/s]\u001b[A\n",
            "model.safetensors:   3% 110M/3.44G [00:02<00:57, 58.4MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 68.8M/3.44G [00:02<02:13, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   3% 119M/3.44G [00:02<01:00, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 73.8M/3.44G [00:02<02:03, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   4% 126M/3.44G [00:02<00:57, 57.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   2% 80.0M/3.44G [00:02<02:11, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   4% 133M/3.44G [00:03<01:15, 43.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 87.4M/3.44G [00:02<01:45, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   4% 140M/3.44G [00:03<01:08, 48.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 92.7M/3.44G [00:03<01:34, 35.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   4% 146M/3.44G [00:03<01:17, 42.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 97.6M/3.44G [00:03<01:38, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   5% 155M/3.44G [00:03<01:05, 50.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 106M/3.44G [00:03<01:17, 43.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   5% 161M/3.44G [00:03<01:29, 36.5MB/s]\u001b[A\n",
            "model.safetensors:   5% 175M/3.44G [00:03<01:00, 53.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   3% 112M/3.44G [00:03<02:03, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 126M/3.44G [00:03<01:15, 43.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   5% 182M/3.44G [00:04<01:14, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 133M/3.44G [00:04<01:21, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 144M/3.44G [00:04<01:02, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   6% 192M/3.44G [00:04<01:16, 42.2MB/s]\u001b[A\n",
            "model.safetensors:   6% 205M/3.44G [00:04<00:57, 56.6MB/s]\u001b[A\n",
            "model.safetensors:   6% 212M/3.44G [00:04<01:06, 48.7MB/s]\u001b[A\n",
            "model.safetensors:   6% 223M/3.44G [00:04<00:53, 60.1MB/s]\u001b[A\n",
            "model.safetensors:   7% 231M/3.44G [00:05<01:06, 48.0MB/s]\u001b[A\n",
            "model.safetensors:   7% 240M/3.44G [00:05<01:20, 39.8MB/s]\u001b[A\n",
            "model.safetensors:   7% 255M/3.44G [00:05<00:57, 55.5MB/s]\u001b[A\n",
            "model.safetensors:   8% 262M/3.44G [00:05<01:09, 45.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   4% 151M/3.44G [00:05<03:44, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   8% 272M/3.44G [00:06<01:22, 38.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 160M/3.44G [00:05<03:05, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   8% 285M/3.44G [00:06<01:00, 52.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 169M/3.44G [00:06<02:21, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   9% 293M/3.44G [00:06<01:04, 48.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   5% 176M/3.44G [00:06<02:09, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 190M/3.44G [00:06<01:24, 38.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   9% 304M/3.44G [00:06<01:11, 43.9MB/s]\u001b[A\n",
            "model.safetensors:   9% 317M/3.44G [00:06<00:55, 55.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 198M/3.44G [00:06<01:24, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 204M/3.44G [00:06<01:15, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:   9% 324M/3.44G [00:07<01:05, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 211M/3.44G [00:06<01:19, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  10% 334M/3.44G [00:07<00:55, 56.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   6% 217M/3.44G [00:06<01:15, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  10% 341M/3.44G [00:07<01:08, 45.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 224M/3.44G [00:07<01:29, 36.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 236M/3.44G [00:07<01:03, 50.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  10% 352M/3.44G [00:07<01:07, 45.8MB/s]\u001b[A\n",
            "model.safetensors:  11% 366M/3.44G [00:07<00:49, 61.8MB/s]\u001b[A\n",
            "model.safetensors:  11% 374M/3.44G [00:07<00:51, 60.0MB/s]\u001b[A\n",
            "model.safetensors:  11% 384M/3.44G [00:08<01:00, 50.9MB/s]\u001b[A\n",
            "model.safetensors:  12% 398M/3.44G [00:08<00:46, 66.1MB/s]\u001b[A\n",
            "model.safetensors:  12% 406M/3.44G [00:08<00:53, 56.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 242M/3.44G [00:08<02:49, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   7% 252M/3.44G [00:08<02:01, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  12% 416M/3.44G [00:08<01:00, 50.4MB/s]\u001b[A\n",
            "model.safetensors:  12% 426M/3.44G [00:08<00:51, 58.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 259M/3.44G [00:08<01:51, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 268M/3.44G [00:08<01:25, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  13% 433M/3.44G [00:09<01:02, 47.9MB/s]\u001b[A\n",
            "model.safetensors:  13% 446M/3.44G [00:09<00:47, 62.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 275M/3.44G [00:08<01:29, 35.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   8% 286M/3.44G [00:09<01:06, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  13% 454M/3.44G [00:09<01:00, 49.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   9% 293M/3.44G [00:09<01:19, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  13% 464M/3.44G [00:09<01:09, 42.9MB/s]\u001b[A\n",
            "model.safetensors:  14% 478M/3.44G [00:09<00:50, 59.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   9% 304M/3.44G [00:09<01:22, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   9% 314M/3.44G [00:09<01:06, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  14% 487M/3.44G [00:10<01:00, 48.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:   9% 320M/3.44G [00:09<01:18, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 334M/3.44G [00:10<00:56, 55.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  14% 496M/3.44G [00:10<01:15, 38.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 342M/3.44G [00:10<01:03, 49.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  15% 507M/3.44G [00:10<01:00, 48.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 348M/3.44G [00:10<01:03, 48.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  15% 514M/3.44G [00:10<01:08, 43.0MB/s]\u001b[A\n",
            "model.safetensors:  15% 528M/3.44G [00:10<00:49, 58.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  10% 354M/3.44G [00:10<01:16, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 365M/3.44G [00:10<00:57, 53.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  16% 536M/3.44G [00:11<00:59, 49.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 372M/3.44G [00:10<01:07, 45.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 382M/3.44G [00:11<00:53, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  16% 544M/3.44G [00:11<01:03, 45.8MB/s]\u001b[A\n",
            "model.safetensors:  16% 556M/3.44G [00:11<00:48, 59.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  11% 389M/3.44G [00:11<01:10, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  16% 564M/3.44G [00:11<00:57, 50.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 399M/3.44G [00:11<00:57, 52.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  17% 571M/3.44G [00:11<00:54, 52.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 406M/3.44G [00:11<01:12, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  17% 577M/3.44G [00:12<01:03, 44.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 414M/3.44G [00:11<01:00, 49.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  17% 586M/3.44G [00:12<00:56, 50.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  12% 421M/3.44G [00:11<01:09, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  17% 592M/3.44G [00:12<01:11, 39.6MB/s]\u001b[A\n",
            "model.safetensors:  18% 606M/3.44G [00:12<00:48, 57.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 432M/3.44G [00:12<01:08, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 446M/3.44G [00:12<00:48, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  18% 614M/3.44G [00:12<01:01, 46.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 454M/3.44G [00:12<01:00, 49.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  18% 624M/3.44G [00:13<01:05, 42.7MB/s]\u001b[A\n",
            "model.safetensors:  19% 637M/3.44G [00:13<00:48, 57.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  13% 464M/3.44G [00:12<01:12, 41.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  14% 478M/3.44G [00:13<00:52, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  19% 645M/3.44G [00:13<01:00, 46.4MB/s]\u001b[A\n",
            "model.safetensors:  19% 656M/3.44G [00:13<00:49, 56.6MB/s]\u001b[A\n",
            "model.safetensors:  19% 663M/3.44G [00:13<00:55, 50.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  14% 486M/3.44G [00:13<01:25, 34.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  20% 672M/3.44G [00:14<01:06, 41.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  14% 496M/3.44G [00:13<01:19, 37.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  20% 685M/3.44G [00:14<00:48, 56.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 504M/3.44G [00:13<01:10, 41.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  20% 693M/3.44G [00:14<00:54, 50.2MB/s]\u001b[A\n",
            "model.safetensors:  20% 704M/3.44G [00:14<00:55, 49.5MB/s]\u001b[A\n",
            "model.safetensors:  21% 718M/3.44G [00:14<00:42, 64.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 512M/3.44G [00:14<01:53, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  15% 526M/3.44G [00:14<01:15, 38.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  21% 726M/3.44G [00:15<01:01, 44.0MB/s]\u001b[A\n",
            "model.safetensors:  21% 736M/3.44G [00:15<00:59, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 534M/3.44G [00:15<01:34, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 747M/3.44G [00:15<00:49, 54.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 539M/3.44G [00:15<01:26, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 545M/3.44G [00:15<01:30, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 755M/3.44G [00:15<01:03, 42.4MB/s]\u001b[A\n",
            "model.safetensors:  22% 762M/3.44G [00:15<00:56, 47.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 553M/3.44G [00:15<01:15, 38.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 559M/3.44G [00:15<01:09, 41.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  16% 565M/3.44G [00:15<01:11, 40.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  22% 769M/3.44G [00:16<01:12, 37.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 572M/3.44G [00:15<01:02, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  23% 776M/3.44G [00:16<01:01, 43.0MB/s]\u001b[A\n",
            "model.safetensors:  23% 784M/3.44G [00:16<00:55, 48.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 577M/3.44G [00:16<01:17, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 591M/3.44G [00:16<00:50, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  23% 790M/3.44G [00:16<01:12, 36.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  17% 598M/3.44G [00:16<01:03, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  23% 800M/3.44G [00:16<01:06, 39.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  18% 608M/3.44G [00:16<00:52, 53.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  23% 808M/3.44G [00:16<00:55, 47.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  18% 614M/3.44G [00:16<01:01, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  24% 816M/3.44G [00:17<01:07, 39.0MB/s]\u001b[A\n",
            "model.safetensors:  24% 830M/3.44G [00:17<00:46, 55.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  18% 624M/3.44G [00:17<01:09, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 639M/3.44G [00:17<00:47, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  24% 837M/3.44G [00:17<01:02, 41.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 647M/3.44G [00:17<00:50, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  24% 843M/3.44G [00:17<00:59, 43.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 653M/3.44G [00:17<00:51, 53.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 849M/3.44G [00:17<01:04, 40.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 660M/3.44G [00:17<00:57, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 860M/3.44G [00:18<00:48, 53.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  19% 665M/3.44G [00:17<00:58, 47.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 867M/3.44G [00:18<01:02, 41.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 672M/3.44G [00:17<01:09, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  25% 876M/3.44G [00:18<00:50, 50.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 680M/3.44G [00:18<01:00, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  26% 883M/3.44G [00:18<01:01, 41.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 688M/3.44G [00:18<01:07, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  26% 894M/3.44G [00:18<00:46, 54.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 696M/3.44G [00:18<00:59, 46.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  26% 901M/3.44G [00:18<00:51, 49.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  20% 704M/3.44G [00:18<01:13, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 912M/3.44G [00:19<00:53, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 716M/3.44G [00:18<00:54, 50.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 921M/3.44G [00:19<00:45, 54.9MB/s]\u001b[A\n",
            "model.safetensors:  27% 928M/3.44G [00:19<00:43, 57.3MB/s]\u001b[A\n",
            "model.safetensors:  27% 934M/3.44G [00:19<00:45, 54.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 722M/3.44G [00:19<01:12, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  27% 942M/3.44G [00:19<00:42, 59.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 730M/3.44G [00:19<01:05, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 948M/3.44G [00:19<00:48, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  21% 736M/3.44G [00:19<01:10, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 959M/3.44G [00:19<00:38, 64.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 746M/3.44G [00:19<00:54, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 967M/3.44G [00:20<00:46, 53.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 752M/3.44G [00:19<01:14, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  28% 976M/3.44G [00:20<00:49, 50.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 761M/3.44G [00:20<01:01, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  29% 985M/3.44G [00:20<00:44, 55.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 767M/3.44G [00:20<00:57, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  29% 992M/3.44G [00:20<00:54, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  22% 773M/3.44G [00:20<01:04, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  29% 1.00G/3.44G [00:20<00:47, 51.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 778M/3.44G [00:20<01:03, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  29% 1.01G/3.44G [00:21<00:57, 42.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 784M/3.44G [00:20<01:15, 35.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  30% 1.02G/3.44G [00:21<00:45, 53.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 791M/3.44G [00:20<01:02, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 797M/3.44G [00:20<00:58, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  30% 1.03G/3.44G [00:21<00:50, 47.5MB/s]\u001b[A\n",
            "model.safetensors:  30% 1.04G/3.44G [00:21<00:37, 63.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  23% 802M/3.44G [00:21<01:12, 36.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 815M/3.44G [00:21<00:47, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  30% 1.05G/3.44G [00:21<00:51, 46.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 822M/3.44G [00:21<01:07, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  31% 1.06G/3.44G [00:21<00:52, 45.4MB/s]\u001b[A\n",
            "model.safetensors:  31% 1.07G/3.44G [00:22<00:44, 53.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 832M/3.44G [00:21<01:00, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  24% 841M/3.44G [00:21<00:50, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  31% 1.07G/3.44G [00:22<00:57, 41.1MB/s]\u001b[A\n",
            "model.safetensors:  32% 1.09G/3.44G [00:22<00:40, 57.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  25% 848M/3.44G [00:22<01:05, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  25% 862M/3.44G [00:22<00:45, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  32% 1.09G/3.44G [00:22<00:46, 50.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  25% 870M/3.44G [00:22<00:52, 49.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  32% 1.10G/3.44G [00:22<00:47, 49.3MB/s]\u001b[A\n",
            "model.safetensors:  32% 1.11G/3.44G [00:22<00:38, 59.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 880M/3.44G [00:22<00:53, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 893M/3.44G [00:22<00:40, 62.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  26% 901M/3.44G [00:23<00:47, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  33% 1.12G/3.44G [00:23<01:05, 35.4MB/s]\u001b[A\n",
            "model.safetensors:  33% 1.13G/3.44G [00:23<00:50, 45.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  27% 912M/3.44G [00:23<00:52, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  27% 926M/3.44G [00:23<00:39, 62.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  33% 1.14G/3.44G [00:23<00:59, 38.8MB/s]\u001b[A\n",
            "model.safetensors:  33% 1.15G/3.44G [00:23<00:46, 49.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  27% 934M/3.44G [00:23<00:47, 53.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  34% 1.16G/3.44G [00:24<00:51, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  27% 944M/3.44G [00:23<00:52, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  28% 956M/3.44G [00:23<00:42, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  34% 1.17G/3.44G [00:24<00:52, 43.2MB/s]\u001b[A\n",
            "model.safetensors:  34% 1.18G/3.44G [00:24<00:37, 59.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  28% 964M/3.44G [00:24<00:54, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  35% 1.19G/3.44G [00:24<00:49, 45.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  28% 976M/3.44G [00:24<00:55, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  35% 1.20G/3.44G [00:25<00:49, 45.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 990M/3.44G [00:24<00:41, 58.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  35% 1.21G/3.44G [00:25<00:41, 53.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 998M/3.44G [00:24<00:53, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  29% 1.01G/3.44G [00:25<00:58, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  30% 1.02G/3.44G [00:25<00:43, 55.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  35% 1.22G/3.44G [00:25<01:26, 25.6MB/s]\u001b[A\n",
            "model.safetensors:  36% 1.23G/3.44G [00:25<00:57, 38.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  30% 1.03G/3.44G [00:25<00:53, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  30% 1.04G/3.44G [00:26<01:01, 38.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.05G/3.44G [00:26<00:45, 52.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  36% 1.24G/3.44G [00:26<01:26, 25.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.06G/3.44G [00:26<00:54, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  36% 1.25G/3.44G [00:26<01:16, 28.7MB/s]\u001b[A\n",
            "model.safetensors:  37% 1.26G/3.44G [00:26<01:02, 34.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  31% 1.07G/3.44G [00:26<00:57, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.09G/3.44G [00:26<00:42, 55.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  37% 1.26G/3.44G [00:27<01:03, 34.3MB/s]\u001b[A\n",
            "model.safetensors:  37% 1.28G/3.44G [00:27<00:47, 45.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.09G/3.44G [00:27<00:52, 45.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  37% 1.28G/3.44G [00:27<00:48, 44.2MB/s]\u001b[A\n",
            "model.safetensors:  37% 1.29G/3.44G [00:27<00:44, 48.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.10G/3.44G [00:27<00:49, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  38% 1.30G/3.44G [00:27<00:43, 49.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.11G/3.44G [00:27<00:57, 41.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  32% 1.12G/3.44G [00:27<00:46, 50.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  38% 1.30G/3.44G [00:27<00:51, 41.2MB/s]\u001b[A\n",
            "model.safetensors:  38% 1.31G/3.44G [00:27<00:47, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  33% 1.12G/3.44G [00:27<00:55, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  33% 1.13G/3.44G [00:27<00:41, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  38% 1.31G/3.44G [00:28<01:02, 34.3MB/s]\u001b[A\n",
            "model.safetensors:  39% 1.33G/3.44G [00:28<00:39, 52.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  33% 1.14G/3.44G [00:28<00:51, 44.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  33% 1.15G/3.44G [00:28<00:41, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  39% 1.33G/3.44G [00:28<00:48, 43.6MB/s]\u001b[A\n",
            "model.safetensors:  39% 1.34G/3.44G [00:28<00:50, 41.6MB/s]\u001b[A\n",
            "model.safetensors:  39% 1.36G/3.44G [00:28<00:37, 56.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.16G/3.44G [00:28<01:07, 33.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 1.37G/3.44G [00:29<00:40, 51.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.17G/3.44G [00:28<01:12, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 1.38G/3.44G [00:29<00:42, 48.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.18G/3.44G [00:29<00:53, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 1.38G/3.44G [00:29<00:38, 53.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  34% 1.19G/3.44G [00:29<01:02, 36.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  40% 1.39G/3.44G [00:29<00:46, 44.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.20G/3.44G [00:29<00:49, 45.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  41% 1.40G/3.44G [00:29<00:40, 49.8MB/s]\u001b[A\n",
            "model.safetensors:  41% 1.41G/3.44G [00:29<00:36, 55.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.20G/3.44G [00:29<00:57, 38.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  35% 1.22G/3.44G [00:29<00:41, 53.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  41% 1.41G/3.44G [00:30<00:49, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.22G/3.44G [00:30<00:46, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  41% 1.42G/3.44G [00:30<00:49, 40.9MB/s]\u001b[A\n",
            "model.safetensors:  42% 1.44G/3.44G [00:30<00:35, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.23G/3.44G [00:30<00:49, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.25G/3.44G [00:30<00:35, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  42% 1.44G/3.44G [00:30<00:39, 50.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  36% 1.25G/3.44G [00:30<00:49, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  42% 1.46G/3.44G [00:31<00:43, 45.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.26G/3.44G [00:30<00:42, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 1.46G/3.44G [00:31<00:39, 49.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.27G/3.44G [00:30<00:45, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 1.47G/3.44G [00:31<00:55, 35.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.28G/3.44G [00:31<00:55, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 1.49G/3.44G [00:31<00:37, 51.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  37% 1.29G/3.44G [00:31<00:44, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  43% 1.49G/3.44G [00:31<00:40, 47.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  38% 1.30G/3.44G [00:31<00:50, 42.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  38% 1.31G/3.44G [00:31<00:37, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  44% 1.50G/3.44G [00:32<00:41, 47.1MB/s]\u001b[A\n",
            "model.safetensors:  44% 1.51G/3.44G [00:32<00:34, 56.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  38% 1.32G/3.44G [00:31<00:40, 51.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  44% 1.52G/3.44G [00:32<00:41, 46.3MB/s]\u001b[A\n",
            "model.safetensors:  45% 1.53G/3.44G [00:32<00:31, 60.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.33G/3.44G [00:32<00:46, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.34G/3.44G [00:32<00:33, 61.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  45% 1.54G/3.44G [00:32<00:35, 53.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  39% 1.35G/3.44G [00:32<00:38, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  45% 1.55G/3.44G [00:33<00:40, 46.8MB/s]\u001b[A\n",
            "model.safetensors:  46% 1.57G/3.44G [00:33<00:29, 63.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.36G/3.44G [00:32<00:49, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 1.57G/3.44G [00:33<00:34, 54.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.37G/3.44G [00:33<00:40, 51.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 1.58G/3.44G [00:33<00:34, 54.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.38G/3.44G [00:33<00:45, 45.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  40% 1.39G/3.44G [00:33<00:34, 59.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 1.59G/3.44G [00:33<00:42, 43.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  41% 1.40G/3.44G [00:33<00:38, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  41% 1.41G/3.44G [00:33<00:43, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  46% 1.60G/3.44G [00:34<00:55, 33.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  41% 1.42G/3.44G [00:33<00:33, 60.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  47% 1.61G/3.44G [00:34<00:47, 39.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  41% 1.43G/3.44G [00:34<00:40, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  47% 1.62G/3.44G [00:34<00:47, 38.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.44G/3.44G [00:34<00:33, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  47% 1.62G/3.44G [00:34<00:40, 44.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.45G/3.44G [00:34<00:41, 47.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  47% 1.63G/3.44G [00:34<00:47, 37.7MB/s]\u001b[A\n",
            "model.safetensors:  48% 1.65G/3.44G [00:35<00:33, 53.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  42% 1.46G/3.44G [00:34<00:43, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.47G/3.44G [00:34<00:33, 59.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  48% 1.65G/3.44G [00:35<00:38, 46.7MB/s]\u001b[A\n",
            "model.safetensors:  48% 1.66G/3.44G [00:35<00:39, 45.3MB/s]\u001b[A\n",
            "model.safetensors:  49% 1.68G/3.44G [00:35<00:28, 61.6MB/s]\u001b[A\n",
            "model.safetensors:  49% 1.69G/3.44G [00:35<00:33, 52.3MB/s]\u001b[A\n",
            "model.safetensors:  49% 1.70G/3.44G [00:36<00:38, 45.3MB/s]\u001b[A\n",
            "model.safetensors:  50% 1.71G/3.44G [00:36<00:28, 61.0MB/s]\u001b[A\n",
            "model.safetensors:  50% 1.72G/3.44G [00:36<00:29, 57.6MB/s]\u001b[A\n",
            "model.safetensors:  50% 1.73G/3.44G [00:36<00:36, 46.6MB/s]\u001b[A\n",
            "model.safetensors:  51% 1.74G/3.44G [00:36<00:27, 60.8MB/s]\u001b[A\n",
            "model.safetensors:  51% 1.75G/3.44G [00:37<00:31, 52.9MB/s]\u001b[A\n",
            "model.safetensors:  51% 1.76G/3.44G [00:37<00:33, 50.9MB/s]\u001b[A\n",
            "model.safetensors:  52% 1.77G/3.44G [00:37<00:25, 66.5MB/s]\u001b[A\n",
            "model.safetensors:  52% 1.78G/3.44G [00:37<00:29, 56.7MB/s]\u001b[A\n",
            "model.safetensors:  52% 1.79G/3.44G [00:37<00:31, 52.1MB/s]\u001b[A\n",
            "model.safetensors:  52% 1.81G/3.44G [00:37<00:23, 68.5MB/s]\u001b[A\n",
            "model.safetensors:  53% 1.82G/3.44G [00:38<00:28, 57.8MB/s]\u001b[A\n",
            "model.safetensors:  53% 1.82G/3.44G [00:38<00:32, 50.0MB/s]\u001b[A\n",
            "model.safetensors:  53% 1.84G/3.44G [00:38<00:24, 64.5MB/s]\u001b[A\n",
            "model.safetensors:  54% 1.85G/3.44G [00:38<00:28, 55.3MB/s]\u001b[A\n",
            "model.safetensors:  54% 1.86G/3.44G [00:39<00:34, 45.8MB/s]\u001b[A\n",
            "model.safetensors:  54% 1.87G/3.44G [00:39<00:26, 60.1MB/s]\u001b[A\n",
            "model.safetensors:  55% 1.88G/3.44G [00:39<00:33, 47.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.48G/3.44G [00:39<04:59, 6.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  55% 1.89G/3.44G [00:39<00:33, 46.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.48G/3.44G [00:39<04:00, 8.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  55% 1.90G/3.44G [00:39<00:30, 50.3MB/s]\u001b[A\n",
            "model.safetensors:  55% 1.90G/3.44G [00:39<00:26, 57.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  43% 1.49G/3.44G [00:39<03:18, 9.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.50G/3.44G [00:39<01:58, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 1.91G/3.44G [00:40<00:37, 40.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.51G/3.44G [00:39<01:46, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 1.92G/3.44G [00:40<00:32, 46.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.52G/3.44G [00:39<01:27, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 1.93G/3.44G [00:40<00:37, 40.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  44% 1.52G/3.44G [00:40<01:24, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.53G/3.44G [00:40<00:58, 32.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  56% 1.94G/3.44G [00:40<00:41, 36.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.54G/3.44G [00:40<00:58, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.95G/3.44G [00:40<00:31, 48.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.55G/3.44G [00:40<00:51, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.95G/3.44G [00:41<00:34, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.55G/3.44G [00:40<00:53, 35.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.97G/3.44G [00:41<00:25, 57.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  45% 1.56G/3.44G [00:40<00:45, 41.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  57% 1.97G/3.44G [00:41<00:31, 46.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  46% 1.57G/3.44G [00:41<00:48, 38.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  46% 1.58G/3.44G [00:41<00:37, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  58% 1.98G/3.44G [00:41<00:30, 47.3MB/s]\u001b[A\n",
            "model.safetensors:  58% 1.99G/3.44G [00:41<00:25, 57.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  46% 1.58G/3.44G [00:41<00:46, 39.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  46% 1.60G/3.44G [00:41<00:32, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  58% 2.00G/3.44G [00:42<00:29, 48.5MB/s]\u001b[A\n",
            "model.safetensors:  58% 2.01G/3.44G [00:42<00:25, 56.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.61G/3.44G [00:41<00:40, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  59% 2.02G/3.44G [00:42<00:30, 47.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.62G/3.44G [00:42<00:33, 53.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  59% 2.02G/3.44G [00:42<00:28, 50.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.62G/3.44G [00:42<00:40, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  59% 2.03G/3.44G [00:42<00:32, 43.0MB/s]\u001b[A\n",
            "model.safetensors:  59% 2.04G/3.44G [00:42<00:25, 55.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  47% 1.63G/3.44G [00:42<00:41, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  48% 1.65G/3.44G [00:42<00:30, 59.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  60% 2.05G/3.44G [00:43<00:31, 44.4MB/s]\u001b[A\n",
            "model.safetensors:  60% 2.06G/3.44G [00:43<00:23, 58.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  48% 1.65G/3.44G [00:42<00:35, 50.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  48% 1.66G/3.44G [00:42<00:29, 59.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  60% 2.07G/3.44G [00:43<00:31, 43.6MB/s]\u001b[A\n",
            "model.safetensors:  60% 2.08G/3.44G [00:43<00:26, 51.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  49% 1.67G/3.44G [00:43<00:38, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  49% 1.68G/3.44G [00:43<00:33, 52.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  61% 2.09G/3.44G [00:43<00:31, 42.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  49% 1.69G/3.44G [00:43<00:42, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  61% 2.10G/3.44G [00:44<00:31, 43.3MB/s]\u001b[A\n",
            "model.safetensors:  61% 2.11G/3.44G [00:44<00:21, 60.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  49% 1.70G/3.44G [00:43<00:40, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 1.71G/3.44G [00:43<00:31, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  62% 2.12G/3.44G [00:44<00:27, 47.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 1.71G/3.44G [00:44<00:35, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 1.72G/3.44G [00:44<00:33, 51.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  62% 2.13G/3.44G [00:44<00:29, 44.4MB/s]\u001b[A\n",
            "model.safetensors:  62% 2.14G/3.44G [00:44<00:22, 58.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  50% 1.73G/3.44G [00:44<00:40, 42.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  51% 1.74G/3.44G [00:44<00:28, 60.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  62% 2.15G/3.44G [00:44<00:24, 52.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  51% 1.75G/3.44G [00:44<00:32, 52.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  63% 2.16G/3.44G [00:45<00:29, 43.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  51% 1.76G/3.44G [00:45<00:35, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  63% 2.17G/3.44G [00:45<00:22, 55.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  51% 1.77G/3.44G [00:45<00:31, 53.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  63% 2.18G/3.44G [00:45<00:24, 51.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  52% 1.78G/3.44G [00:45<00:35, 46.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 2.19G/3.44G [00:45<00:19, 63.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  52% 1.79G/3.44G [00:45<00:27, 59.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 2.20G/3.44G [00:45<00:22, 54.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  52% 1.80G/3.44G [00:45<00:28, 57.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 2.21G/3.44G [00:46<00:21, 56.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  52% 1.80G/3.44G [00:45<00:28, 57.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  64% 2.21G/3.44G [00:46<00:27, 44.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 1.81G/3.44G [00:45<00:34, 47.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  65% 2.22G/3.44G [00:46<00:23, 50.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 1.82G/3.44G [00:46<00:31, 51.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 1.82G/3.44G [00:46<00:28, 56.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  65% 2.23G/3.44G [00:46<00:27, 44.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 1.83G/3.44G [00:46<00:39, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  65% 2.24G/3.44G [00:46<00:28, 41.7MB/s]\u001b[A\n",
            "model.safetensors:  65% 2.25G/3.44G [00:46<00:20, 57.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  53% 1.84G/3.44G [00:46<00:40, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  54% 1.85G/3.44G [00:46<00:28, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  66% 2.26G/3.44G [00:47<00:27, 42.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  54% 1.86G/3.44G [00:46<00:32, 48.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  66% 2.27G/3.44G [00:47<00:25, 46.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  54% 1.87G/3.44G [00:47<00:29, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  66% 2.27G/3.44G [00:47<00:28, 40.7MB/s]\u001b[A\n",
            "model.safetensors:  66% 2.29G/3.44G [00:47<00:20, 55.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  54% 1.87G/3.44G [00:47<00:41, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  67% 2.29G/3.44G [00:47<00:25, 44.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  55% 1.89G/3.44G [00:47<00:34, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  67% 2.30G/3.44G [00:48<00:22, 50.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  55% 1.90G/3.44G [00:47<00:31, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  67% 2.31G/3.44G [00:48<00:25, 43.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  55% 1.90G/3.44G [00:47<00:35, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  67% 2.32G/3.44G [00:48<00:19, 57.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  56% 1.91G/3.44G [00:48<00:31, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  68% 2.33G/3.44G [00:48<00:22, 48.7MB/s]\u001b[A\n",
            "model.safetensors:  68% 2.34G/3.44G [00:48<00:26, 41.1MB/s]\u001b[A\n",
            "model.safetensors:  68% 2.35G/3.44G [00:49<00:19, 56.7MB/s]\u001b[A\n",
            "model.safetensors:  68% 2.36G/3.44G [00:49<00:23, 45.8MB/s]\u001b[A\n",
            "model.safetensors:  69% 2.37G/3.44G [00:49<00:18, 57.0MB/s]\u001b[A\n",
            "model.safetensors:  69% 2.38G/3.44G [00:49<00:23, 45.8MB/s]\u001b[A\n",
            "model.safetensors:  69% 2.38G/3.44G [00:49<00:25, 40.8MB/s]\u001b[A\n",
            "model.safetensors:  70% 2.40G/3.44G [00:50<00:18, 56.5MB/s]\u001b[A\n",
            "model.safetensors:  70% 2.41G/3.44G [00:50<00:22, 46.5MB/s]\u001b[A\n",
            "model.safetensors:  70% 2.42G/3.44G [00:50<00:22, 44.6MB/s]\u001b[A\n",
            "model.safetensors:  71% 2.43G/3.44G [00:50<00:17, 59.5MB/s]\u001b[A\n",
            "model.safetensors:  71% 2.44G/3.44G [00:50<00:18, 53.6MB/s]\u001b[A\n",
            "model.safetensors:  71% 2.45G/3.44G [00:51<00:20, 47.6MB/s]\u001b[A\n",
            "model.safetensors:  72% 2.46G/3.44G [00:51<00:15, 62.0MB/s]\u001b[A\n",
            "model.safetensors:  72% 2.47G/3.44G [00:51<00:17, 56.2MB/s]\u001b[A\n",
            "model.safetensors:  72% 2.48G/3.44G [00:51<00:19, 50.5MB/s]\u001b[A\n",
            "model.safetensors:  72% 2.49G/3.44G [00:51<00:14, 65.8MB/s]\u001b[A\n",
            "model.safetensors:  73% 2.50G/3.44G [00:51<00:15, 59.5MB/s]\u001b[A\n",
            "model.safetensors:  73% 2.51G/3.44G [00:52<00:18, 50.4MB/s]\u001b[A\n",
            "model.safetensors:  73% 2.53G/3.44G [00:52<00:14, 64.8MB/s]\u001b[A\n",
            "model.safetensors:  74% 2.53G/3.44G [00:52<00:19, 47.1MB/s]\u001b[A\n",
            "model.safetensors:  74% 2.54G/3.44G [00:52<00:21, 42.3MB/s]\u001b[A\n",
            "model.safetensors:  74% 2.56G/3.44G [00:53<00:15, 56.0MB/s]\u001b[A\n",
            "model.safetensors:  75% 2.57G/3.44G [00:53<00:17, 50.6MB/s]\u001b[A\n",
            "model.safetensors:  75% 2.58G/3.44G [00:53<00:18, 47.3MB/s]\u001b[A\n",
            "model.safetensors:  75% 2.59G/3.44G [00:53<00:13, 62.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  56% 1.92G/3.44G [00:53<05:02, 5.03MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  56% 1.93G/3.44G [00:53<03:39, 6.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  75% 2.60G/3.44G [00:53<00:15, 53.5MB/s]\u001b[A\n",
            "model.safetensors:  76% 2.60G/3.44G [00:53<00:15, 55.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  56% 1.94G/3.44G [00:53<02:50, 8.83MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  76% 2.61G/3.44G [00:54<00:16, 50.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  57% 1.95G/3.44G [00:53<01:48, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  76% 2.62G/3.44G [00:54<00:15, 51.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  57% 1.95G/3.44G [00:54<01:37, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  57% 1.97G/3.44G [00:54<01:04, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  76% 2.62G/3.44G [00:54<00:24, 33.0MB/s]\u001b[A\n",
            "model.safetensors:  77% 2.64G/3.44G [00:54<00:16, 49.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  57% 1.97G/3.44G [00:54<01:01, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 2.64G/3.44G [00:54<00:16, 48.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 1.98G/3.44G [00:54<00:46, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 2.65G/3.44G [00:54<00:14, 53.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 1.99G/3.44G [00:54<00:44, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  77% 2.66G/3.44G [00:55<00:17, 44.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 2.00G/3.44G [00:54<00:40, 36.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  78% 2.67G/3.44G [00:55<00:12, 59.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  58% 2.01G/3.44G [00:54<00:34, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  78% 2.68G/3.44G [00:55<00:15, 48.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  59% 2.02G/3.44G [00:55<00:35, 40.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  59% 2.03G/3.44G [00:55<00:27, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  78% 2.69G/3.44G [00:55<00:16, 46.0MB/s]\u001b[A\n",
            "model.safetensors:  78% 2.70G/3.44G [00:55<00:12, 59.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  59% 2.03G/3.44G [00:55<00:31, 45.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  59% 2.05G/3.44G [00:55<00:22, 62.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  79% 2.71G/3.44G [00:56<00:14, 50.0MB/s]\u001b[A\n",
            "model.safetensors:  79% 2.72G/3.44G [00:56<00:11, 61.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  60% 2.06G/3.44G [00:55<00:27, 49.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  79% 2.73G/3.44G [00:56<00:13, 51.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  60% 2.06G/3.44G [00:56<00:30, 45.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  60% 2.08G/3.44G [00:56<00:21, 62.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  80% 2.74G/3.44G [00:56<00:14, 47.8MB/s]\u001b[A\n",
            "model.safetensors:  80% 2.75G/3.44G [00:56<00:10, 64.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  61% 2.09G/3.44G [00:56<00:26, 51.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  80% 2.76G/3.44G [00:56<00:13, 51.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  61% 2.10G/3.44G [00:56<00:29, 46.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  80% 2.77G/3.44G [00:57<00:13, 51.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  61% 2.11G/3.44G [00:56<00:21, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  81% 2.78G/3.44G [00:57<00:11, 56.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  62% 2.12G/3.44G [00:57<00:24, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  81% 2.78G/3.44G [00:57<00:14, 43.8MB/s]\u001b[A\n",
            "model.safetensors:  81% 2.80G/3.44G [00:57<00:10, 59.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  62% 2.13G/3.44G [00:57<00:28, 46.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  62% 2.14G/3.44G [00:57<00:22, 57.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  82% 2.81G/3.44G [00:57<00:12, 48.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  62% 2.15G/3.44G [00:57<00:30, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  82% 2.82G/3.44G [00:58<00:13, 45.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.16G/3.44G [00:57<00:23, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  82% 2.82G/3.44G [00:58<00:12, 51.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.17G/3.44G [00:58<00:25, 50.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  82% 2.83G/3.44G [00:58<00:12, 47.2MB/s]\u001b[A\n",
            "model.safetensors:  83% 2.84G/3.44G [00:58<00:09, 60.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  63% 2.18G/3.44G [00:58<00:26, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  64% 2.19G/3.44G [00:58<00:20, 60.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  83% 2.85G/3.44G [00:58<00:10, 53.9MB/s]\u001b[A\n",
            "model.safetensors:  83% 2.86G/3.44G [00:58<00:08, 66.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  64% 2.19G/3.44G [00:58<00:25, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  83% 2.87G/3.44G [00:59<00:10, 52.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  64% 2.21G/3.44G [00:58<00:25, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  65% 2.22G/3.44G [00:58<00:19, 63.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  84% 2.88G/3.44G [00:59<00:12, 44.5MB/s]\u001b[A\n",
            "model.safetensors:  84% 2.89G/3.44G [00:59<00:09, 60.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  65% 2.23G/3.44G [00:59<00:23, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  84% 2.90G/3.44G [00:59<00:10, 51.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  65% 2.24G/3.44G [00:59<00:24, 48.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.25G/3.44G [00:59<00:18, 64.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  85% 2.91G/3.44G [01:00<00:13, 39.8MB/s]\u001b[A\n",
            "model.safetensors:  85% 2.92G/3.44G [01:00<00:10, 50.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.26G/3.44G [00:59<00:24, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.27G/3.44G [00:59<00:22, 51.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.28G/3.44G [01:00<00:26, 44.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  85% 2.93G/3.44G [01:00<00:15, 33.1MB/s]\u001b[A\n",
            "model.safetensors:  86% 2.94G/3.44G [01:00<00:10, 45.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  66% 2.29G/3.44G [01:00<00:25, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  67% 2.30G/3.44G [01:00<00:18, 61.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  86% 2.95G/3.44G [01:01<00:13, 37.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  67% 2.31G/3.44G [01:00<00:21, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  86% 2.96G/3.44G [01:01<00:11, 41.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  67% 2.32G/3.44G [01:00<00:20, 53.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  86% 2.96G/3.44G [01:01<00:12, 37.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.32G/3.44G [01:01<00:24, 46.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  86% 2.97G/3.44G [01:01<00:10, 45.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.33G/3.44G [01:01<00:23, 47.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  87% 2.98G/3.44G [01:01<00:11, 39.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.34G/3.44G [01:01<00:28, 39.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  87% 2.99G/3.44G [01:01<00:08, 55.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.34G/3.44G [01:01<00:23, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  87% 3.00G/3.44G [01:02<00:09, 48.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  68% 2.35G/3.44G [01:01<00:31, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  69% 2.37G/3.44G [01:01<00:20, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  87% 3.01G/3.44G [01:02<00:14, 29.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  69% 2.37G/3.44G [01:02<00:24, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  69% 2.38G/3.44G [01:02<00:20, 50.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  88% 3.02G/3.44G [01:02<00:12, 34.6MB/s]\u001b[A\n",
            "model.safetensors:  88% 3.02G/3.44G [01:02<00:10, 41.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  69% 2.39G/3.44G [01:02<00:25, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.40G/3.44G [01:02<00:20, 51.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  88% 3.03G/3.44G [01:03<00:11, 34.3MB/s]\u001b[A\n",
            "model.safetensors:  88% 3.04G/3.44G [01:03<00:08, 45.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.41G/3.44G [01:02<00:25, 40.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  89% 3.05G/3.44G [01:03<00:10, 36.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  70% 2.42G/3.44G [01:03<00:24, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.43G/3.44G [01:03<00:18, 55.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  89% 3.06G/3.44G [01:03<00:10, 36.0MB/s]\u001b[A\n",
            "model.safetensors:  89% 3.07G/3.44G [01:03<00:07, 51.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.43G/3.44G [01:03<00:20, 48.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.44G/3.44G [01:03<00:17, 56.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  89% 3.08G/3.44G [01:04<00:08, 43.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  71% 2.45G/3.44G [01:03<00:22, 44.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  90% 3.09G/3.44G [01:04<00:07, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  72% 2.46G/3.44G [01:03<00:16, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  90% 3.10G/3.44G [01:04<00:06, 55.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  72% 2.47G/3.44G [01:04<00:19, 50.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  90% 3.11G/3.44G [01:04<00:06, 49.1MB/s]\u001b[A\n",
            "model.safetensors:  91% 3.12G/3.44G [01:04<00:05, 61.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  72% 2.48G/3.44G [01:04<00:24, 39.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 3.12G/3.44G [01:04<00:06, 47.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  72% 2.49G/3.44G [01:04<00:18, 50.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 3.13G/3.44G [01:05<00:06, 49.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 2.50G/3.44G [01:04<00:22, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 3.14G/3.44G [01:05<00:06, 45.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 2.51G/3.44G [01:05<00:19, 46.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  91% 3.14G/3.44G [01:05<00:06, 49.0MB/s]\u001b[A\n",
            "model.safetensors:  92% 3.15G/3.44G [01:05<00:05, 54.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 2.51G/3.44G [01:05<00:23, 38.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  92% 3.16G/3.44G [01:05<00:06, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 2.52G/3.44G [01:05<00:18, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  92% 3.17G/3.44G [01:05<00:05, 46.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  73% 2.53G/3.44G [01:05<00:22, 40.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  92% 3.17G/3.44G [01:05<00:06, 44.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 2.54G/3.44G [01:05<00:17, 50.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  92% 3.18G/3.44G [01:06<00:05, 48.4MB/s]\u001b[A\n",
            "model.safetensors:  93% 3.18G/3.44G [01:06<00:05, 51.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 2.54G/3.44G [01:05<00:21, 40.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 2.56G/3.44G [01:06<00:16, 54.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  93% 3.19G/3.44G [01:06<00:06, 40.5MB/s]\u001b[A\n",
            "model.safetensors:  93% 3.20G/3.44G [01:06<00:05, 43.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  74% 2.56G/3.44G [01:06<00:18, 47.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  93% 3.20G/3.44G [01:06<00:07, 33.5MB/s]\u001b[A\n",
            "model.safetensors:  93% 3.21G/3.44G [01:06<00:04, 53.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  75% 2.58G/3.44G [01:06<00:18, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  75% 2.59G/3.44G [01:06<00:14, 58.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  94% 3.22G/3.44G [01:07<00:05, 42.4MB/s]\u001b[A\n",
            "model.safetensors:  94% 3.23G/3.44G [01:07<00:03, 55.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  75% 2.59G/3.44G [01:07<00:22, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  76% 2.60G/3.44G [01:07<00:18, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  94% 3.24G/3.44G [01:07<00:04, 43.0MB/s]\u001b[A\n",
            "model.safetensors:  94% 3.24G/3.44G [01:07<00:04, 45.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  76% 2.61G/3.44G [01:07<00:20, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  76% 2.62G/3.44G [01:07<00:14, 56.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  76% 2.63G/3.44G [01:07<00:18, 44.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  77% 2.64G/3.44G [01:07<00:18, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  77% 2.65G/3.44G [01:08<00:13, 59.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  94% 3.25G/3.44G [01:08<00:10, 18.0MB/s]\u001b[A\n",
            "model.safetensors:  95% 3.26G/3.44G [01:08<00:06, 27.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  77% 2.66G/3.44G [01:08<00:15, 49.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  78% 2.67G/3.44G [01:08<00:13, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  95% 3.27G/3.44G [01:08<00:06, 28.1MB/s]\u001b[A\n",
            "model.safetensors:  95% 3.28G/3.44G [01:08<00:04, 40.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  78% 2.68G/3.44G [01:08<00:17, 44.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  96% 3.29G/3.44G [01:09<00:04, 36.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  78% 2.69G/3.44G [01:08<00:17, 42.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.70G/3.44G [01:09<00:12, 57.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  96% 3.30G/3.44G [01:09<00:04, 33.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.71G/3.44G [01:09<00:14, 51.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  96% 3.31G/3.44G [01:09<00:02, 46.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.72G/3.44G [01:09<00:13, 52.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  96% 3.32G/3.44G [01:09<00:02, 42.6MB/s]\u001b[A\n",
            "model.safetensors:  97% 3.33G/3.44G [01:09<00:02, 54.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.72G/3.44G [01:09<00:18, 39.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  79% 2.74G/3.44G [01:09<00:12, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  97% 3.33G/3.44G [01:10<00:02, 36.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  80% 2.74G/3.44G [01:10<00:18, 37.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  97% 3.34G/3.44G [01:10<00:02, 35.5MB/s]\u001b[A\n",
            "model.safetensors:  98% 3.36G/3.44G [01:10<00:01, 49.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  80% 2.75G/3.44G [01:10<00:22, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  80% 2.77G/3.44G [01:10<00:15, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  98% 3.36G/3.44G [01:11<00:01, 38.7MB/s]\u001b[A\n",
            "model.safetensors:  98% 3.37G/3.44G [01:11<00:01, 44.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  81% 2.77G/3.44G [01:10<00:15, 42.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  81% 2.78G/3.44G [01:10<00:12, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  98% 3.38G/3.44G [01:11<00:01, 40.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  81% 2.79G/3.44G [01:11<00:14, 46.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  99% 3.39G/3.44G [01:11<00:01, 42.0MB/s]\u001b[A\n",
            "model.safetensors:  99% 3.41G/3.44G [01:11<00:00, 56.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  81% 2.80G/3.44G [01:11<00:14, 44.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 2.81G/3.44G [01:11<00:11, 56.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors:  99% 3.41G/3.44G [01:11<00:00, 47.4MB/s]\u001b[A\n",
            "model.safetensors:  99% 3.42G/3.44G [01:12<00:00, 58.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 2.82G/3.44G [01:11<00:13, 47.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 2.83G/3.44G [01:11<00:10, 57.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 3.43G/3.44G [01:12<00:00, 44.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  82% 2.84G/3.44G [01:12<00:13, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  83% 2.84G/3.44G [01:12<00:11, 52.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model.safetensors: 100% 3.44G/3.44G [01:12<00:00, 42.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 3.44G/3.44G [01:12<00:00, 47.3MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  83% 2.86G/3.44G [01:12<00:09, 61.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  83% 2.87G/3.44G [01:12<00:10, 54.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "Upload 11 LFS files:   9% 1/11 [01:13<12:10, 73.05s/it]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 2.88G/3.44G [01:12<00:11, 48.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 2.89G/3.44G [01:12<00:08, 65.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  84% 2.90G/3.44G [01:13<00:10, 51.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  85% 2.91G/3.44G [01:13<00:12, 42.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  85% 2.93G/3.44G [01:13<00:09, 57.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  85% 2.93G/3.44G [01:13<00:09, 54.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 2.94G/3.44G [01:14<00:09, 54.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 2.96G/3.44G [01:14<00:06, 69.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 2.97G/3.44G [01:14<00:08, 53.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  86% 2.98G/3.44G [01:14<00:09, 46.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  87% 2.99G/3.44G [01:14<00:07, 62.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  87% 3.00G/3.44G [01:15<00:08, 55.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  87% 3.01G/3.44G [01:15<00:09, 47.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  88% 3.02G/3.44G [01:15<00:06, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  88% 3.03G/3.44G [01:15<00:08, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  88% 3.04G/3.44G [01:15<00:08, 45.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.05G/3.44G [01:16<00:06, 61.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.06G/3.44G [01:16<00:07, 50.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  89% 3.07G/3.44G [01:16<00:07, 47.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.09G/3.44G [01:16<00:05, 63.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.09G/3.44G [01:16<00:05, 62.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  90% 3.10G/3.44G [01:16<00:06, 53.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  91% 3.12G/3.44G [01:17<00:04, 68.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  91% 3.13G/3.44G [01:17<00:05, 57.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  91% 3.14G/3.44G [01:17<00:06, 49.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.15G/3.44G [01:17<00:04, 64.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.16G/3.44G [01:17<00:04, 58.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.17G/3.44G [01:18<00:04, 58.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  92% 3.18G/3.44G [01:18<00:03, 73.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  93% 3.19G/3.44G [01:18<00:05, 49.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  93% 3.20G/3.44G [01:18<00:05, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  93% 3.21G/3.44G [01:18<00:04, 54.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.22G/3.44G [01:19<00:04, 52.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.23G/3.44G [01:19<00:04, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  94% 3.25G/3.44G [01:19<00:03, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.26G/3.44G [01:19<00:03, 55.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.26G/3.44G [01:19<00:03, 48.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  95% 3.28G/3.44G [01:20<00:02, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  96% 3.29G/3.44G [01:20<00:02, 52.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  96% 3.30G/3.44G [01:20<00:03, 48.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  96% 3.31G/3.44G [01:20<00:02, 62.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  96% 3.32G/3.44G [01:20<00:02, 53.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  97% 3.33G/3.44G [01:21<00:02, 52.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  97% 3.34G/3.44G [01:21<00:01, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  97% 3.35G/3.44G [01:21<00:01, 59.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  98% 3.36G/3.44G [01:21<00:01, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  98% 3.37G/3.44G [01:21<00:01, 64.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  98% 3.38G/3.44G [01:22<00:01, 32.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  99% 3.39G/3.44G [01:22<00:01, 34.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  99% 3.41G/3.44G [01:22<00:00, 47.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  99% 3.41G/3.44G [01:22<00:00, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors:  99% 3.42G/3.44G [01:23<00:00, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model.safetensors: 100% 3.44G/3.44G [01:23<00:00, 41.1MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Upload 11 LFS files: 100% 11/11 [01:24<00:00,  7.65s/it]\n",
            "Steps: 100% 400/400 [39:22<00:00,  5.91s/it, lr=0, step_loss=0.00432]\n"
          ]
        }
      ],
      "source": [
        "# !accelerate launch diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "#   --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "#   --dataset_name=$DATASET_NAME \\\n",
        "#   --num_train_epochs=3 \\\n",
        "#   --use_ema \\\n",
        "#   --resolution=512 --center_crop --random_flip \\\n",
        "#   --train_batch_size=1 \\\n",
        "#   --gradient_accumulation_steps=4 \\\n",
        "#   --gradient_checkpointing \\\n",
        "#   --mixed_precision=\"fp16\" \\\n",
        "#   --max_train_steps=400 \\\n",
        "#   --learning_rate=1e-05 \\\n",
        "#   --max_grad_norm=1 \\\n",
        "#   --push_to_hub \\\n",
        "#   --checkpointing_steps=100000 \\\n",
        "#   --lr_scheduler=\"constant\" \\\n",
        "#   --lr_warmup_steps=0 \\\n",
        "#   --output_dir=$OUTPUT_DIR\n",
        "\n",
        "!accelerate launch diffusers/examples/text_to_image/train_text_to_image_lora.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --dataset_name=$DATASET_NAME \\\n",
        "  --dataloader_num_workers=4 \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=4 \\\n",
        "  --max_train_steps=400 \\\n",
        "  --learning_rate=1e-04 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --lr_scheduler=\"cosine\" --lr_warmup_steps=0 \\\n",
        "  --output_dir=${OUTPUT_DIR} \\\n",
        "  --push_to_hub \\\n",
        "  --hub_model_id=${HUB_MODEL_ID} \\\n",
        "  --report_to=wandb \\\n",
        "  --checkpointing_steps=200 \\\n",
        "  --validation_prompt=\"A man in black jacket\" \\\n",
        "  --seed=1337"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xwp9K_EeSJEh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsUCfLNvSMKW"
      },
      "source": [
        "#2nd Try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xB3ihIT6WVe7",
        "outputId": "0659f616-a7d2-4089-8be0-db12dd97b003"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
            "  deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "import peft\n",
        "from peft import LoraConfig, get_peft_model, PeftModel\n",
        "import bitsandbytes as bnb\n",
        "from transformers import Trainer, TrainingArguments"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLtSQ87lWdH4"
      },
      "source": [
        "#Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "332e771354b643faaeab5d344a78bfb8",
            "5b7d306127724ccba0fa77b720170fd0",
            "90c9c339c660467381b5776ecb9d3372",
            "79a52f309a9940798e82b31210b63d50",
            "4be3307b70784bd4a418be01c56bcc8b",
            "98cb0a48c48c43b59efa247a7ffd6f9d",
            "2cea892d49f74c0bbc584d7f3c42c620",
            "a5cdb76dbb0b4651a389ad7096e2dc7a",
            "62f49cfea41f44fcb1f2745bf857cb1f",
            "4ca1cc19c02d43a4bab16d37316252cc",
            "c8f8534da6604a6caf2857ef4cde3535",
            "e9be71ec6215422fba8f7454f865e074",
            "69dd2ddfc65e44bba698fb435d64063d",
            "f6d30505e82f4c5e8a2d486650da8888",
            "3a2a0bd93881414cbbd093354c5b86ef",
            "fbf1eda74a214234b24eb447ce45fd2a",
            "09272ec727d141a684e3aa2c1c1fa961",
            "fc66f926b32c4d91a85d0eb32732e74e",
            "0313b9bf7f1f4704a361b78c9014038e",
            "d144318d066e49a2bb9a2ce99642d4ec",
            "88aa3f9c7fe7427390258cb328b15963",
            "0c6e0e169237499e97c2a577c8a853db",
            "ddeadbee7bd543d18b0083c89b06be43",
            "87aa915f8fae48f69715c37a417c1e83",
            "e7b94460c7554552a00e430b41c832fa",
            "cf952a6f8b7e46199b57f1502b505670",
            "63d8b161b7ea4b8787aaaf0f7c136653",
            "044750774be240418376bed2545f3ccd",
            "eb6b193bb2074846ac8d62930e5bdc07",
            "78da4ccaeca349ada0190cf005858f4a",
            "e8b881ca928d4b1596431fbc2726450b",
            "3315660504f84d1d8a7bf010d06aeb70",
            "10fa10b232ee430a8921f8410eccaf9b",
            "a30bea78cff54db2af3846ebc456f3e9",
            "0d74bfa26af846e6b927daa9cb0910ba",
            "1db1bfd49be84fb495bbfb12f6e7613f",
            "35c7b2029dd44d1aa14d43109776232f",
            "3f4ac1f2312143cbbf1ab4cf61503a0c",
            "cda774e3faf749eb997d7506f41b24fa",
            "ff63cde3a2d5437887695f52169550d7",
            "eeeecaf2be5a4626bde68b507d84340d",
            "364628f805ee47db9e1b351421762df2",
            "bc775a698c1b4e35a5bcef4a8c114a70",
            "88dad9ccb0e44280b16d1d61bcebfdfb",
            "9bf64c49d20c4218a4d099a239f1f980",
            "7be81ad13f2e40079949be1e2fefeb76",
            "ffb755f925914e409181eaf878178a2e",
            "568f9d64f9444cac884f78838e3b40a4",
            "18f7e4d9c265400fa37765ee4ae4099a",
            "4191b4a6a06c424c83f83f1a55e32ee3",
            "5b9cd79349d44a09a408b8466bdf7849",
            "b6b011fd3010464688f1854f4054ec64",
            "88fa1d35b4294d2db9a2640373527c8d",
            "29f090164a0d4ada80245b26d050b6a4",
            "4cca69fefba444b5ad0b965ebf26ad55",
            "75a1cb04d8fd4864b5405078eeceabf2",
            "ce6436a5058e4c489758d88ca260855f",
            "881d82ae65a347efaa941c60cf9154d1",
            "d83ede0f158648f691d70a6150af33cd",
            "924a3a3a1268445b8f370cbfe6132673",
            "49b4359818414a4e8cf6e658112c0d7f",
            "704016009fd647f8bc70a22aace71703",
            "32194941dd784d92acc0a732d226fac7",
            "ec8932bfcc964c358cb4b4372ff89ccd",
            "d4bb4ceaca3f4f87942e51745819a82c",
            "e9e7be631911449d93074654bae1be53"
          ]
        },
        "collapsed": true,
        "id": "A39eo-coWVle",
        "outputId": "5a96b490-e31d-4100-e6c5-c2f26fea6ec3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "332e771354b643faaeab5d344a78bfb8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/836 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9be71ec6215422fba8f7454f865e074",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/363M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddeadbee7bd543d18b0083c89b06be43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/364M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a30bea78cff54db2af3846ebc456f3e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/361M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9bf64c49d20c4218a4d099a239f1f980",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/361M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75a1cb04d8fd4864b5405078eeceabf2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/40658 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset = load_dataset('SaffalPoosh/deepFashion-with-masks')\n",
        "dataset = dataset['train'].remove_columns(['pose', 'cloth_type', 'pid', 'mask', 'mask_overlay'])\n",
        "dataset = dataset.rename_column('caption', 'text')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "395vIiHKWWN_"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.shuffle(seed=42).select(range(200))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_gTraQNX7Zc"
      },
      "source": [
        "#Import the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "fb297017829a4dca969c53460dfc8c37",
            "58bcbf558bfc4a09b092099e7f277f6b",
            "177eec2a054a4cd3b830165cc354a145",
            "e717354177344a5ab7157f492bf31764",
            "8e2d967fba8442fda3e591572aaa51bc",
            "aa2baca4ea57447b9f06a62e24ed5f57",
            "b6200243d12840659f3002dee4c0ff8e",
            "4c45e77c7a614af18175d7ef018f49a4",
            "c78bf7ef1fe14abca6d9b9c63cc55199",
            "fa54c34c801242beaa7d73e1399d54d3",
            "d54c47f31de04ff6b84aeeabe8be47ab"
          ]
        },
        "id": "TCGR7BnwWstf",
        "outputId": "49584841-2036-4c12-f2f4-2b4521a20689"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fb297017829a4dca969c53460dfc8c37",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8tk7O7Mua15L",
        "outputId": "06b3a913-dba5-474d-a05d-263d6dc4f056"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "StableDiffusionPipeline {\n",
              "  \"_class_name\": \"StableDiffusionPipeline\",\n",
              "  \"_diffusers_version\": \"0.28.2\",\n",
              "  \"_name_or_path\": \"runwayml/stable-diffusion-v1-5\",\n",
              "  \"feature_extractor\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPImageProcessor\"\n",
              "  ],\n",
              "  \"image_encoder\": [\n",
              "    null,\n",
              "    null\n",
              "  ],\n",
              "  \"requires_safety_checker\": true,\n",
              "  \"safety_checker\": [\n",
              "    \"stable_diffusion\",\n",
              "    \"StableDiffusionSafetyChecker\"\n",
              "  ],\n",
              "  \"scheduler\": [\n",
              "    \"diffusers\",\n",
              "    \"PNDMScheduler\"\n",
              "  ],\n",
              "  \"text_encoder\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTextModel\"\n",
              "  ],\n",
              "  \"tokenizer\": [\n",
              "    \"transformers\",\n",
              "    \"CLIPTokenizer\"\n",
              "  ],\n",
              "  \"unet\": [\n",
              "    \"diffusers\",\n",
              "    \"UNet2DConditionModel\"\n",
              "  ],\n",
              "  \"vae\": [\n",
              "    \"diffusers\",\n",
              "    \"AutoencoderKL\"\n",
              "  ]\n",
              "}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QRP9S05qZEbq",
        "outputId": "06c07489-9d84-4de6-bc86-d5c4e6c343f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "CLIPTextModel(\n",
              "  (text_model): CLIPTextTransformer(\n",
              "    (embeddings): CLIPTextEmbeddings(\n",
              "      (token_embedding): Embedding(49408, 768)\n",
              "      (position_embedding): Embedding(77, 768)\n",
              "    )\n",
              "    (encoder): CLIPEncoder(\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x CLIPEncoderLayer(\n",
              "          (self_attn): CLIPAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (mlp): CLIPMLP(\n",
              "            (activation_fn): QuickGELUActivation()\n",
              "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          )\n",
              "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe.text_encoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IL96HPp8a0H-",
        "outputId": "ba98eab7-0b69-4a36-ad92-b61f46da4778"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "UNet2DConditionModel(\n",
              "  (conv_in): Conv2d(4, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (time_proj): Timesteps()\n",
              "  (time_embedding): TimestepEmbedding(\n",
              "    (linear_1): Linear(in_features=320, out_features=1280, bias=True)\n",
              "    (act): SiLU()\n",
              "    (linear_2): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "  )\n",
              "  (down_blocks): ModuleList(\n",
              "    (0): CrossAttnDownBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-1): 2 x Transformer2DModel(\n",
              "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
              "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (transformer_blocks): ModuleList(\n",
              "            (0): BasicTransformerBlock(\n",
              "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn1): Attention(\n",
              "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn2): Attention(\n",
              "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
              "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (ff): FeedForward(\n",
              "                (net): ModuleList(\n",
              "                  (0): GEGLU(\n",
              "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
              "                  )\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "      (downsamplers): ModuleList(\n",
              "        (0): Downsample2D(\n",
              "          (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): CrossAttnDownBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-1): 2 x Transformer2DModel(\n",
              "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
              "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (transformer_blocks): ModuleList(\n",
              "            (0): BasicTransformerBlock(\n",
              "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn1): Attention(\n",
              "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn2): Attention(\n",
              "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
              "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "              (ff): FeedForward(\n",
              "                (net): ModuleList(\n",
              "                  (0): GEGLU(\n",
              "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
              "                  )\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
              "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
              "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "      (downsamplers): ModuleList(\n",
              "        (0): Downsample2D(\n",
              "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): CrossAttnDownBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-1): 2 x Transformer2DModel(\n",
              "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
              "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (transformer_blocks): ModuleList(\n",
              "            (0): BasicTransformerBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn1): Attention(\n",
              "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn2): Attention(\n",
              "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
              "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (ff): FeedForward(\n",
              "                (net): ModuleList(\n",
              "                  (0): GEGLU(\n",
              "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
              "                  )\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(640, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(640, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "      (downsamplers): ModuleList(\n",
              "        (0): Downsample2D(\n",
              "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): DownBlock2D(\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (up_blocks): ModuleList(\n",
              "    (0): UpBlock2D(\n",
              "      (resnets): ModuleList(\n",
              "        (0-2): 3 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (upsamplers): ModuleList(\n",
              "        (0): Upsample2D(\n",
              "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (1): CrossAttnUpBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-2): 3 x Transformer2DModel(\n",
              "          (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
              "          (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (transformer_blocks): ModuleList(\n",
              "            (0): BasicTransformerBlock(\n",
              "              (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn1): Attention(\n",
              "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn2): Attention(\n",
              "                (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "                (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
              "                (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "              (ff): FeedForward(\n",
              "                (net): ModuleList(\n",
              "                  (0): GEGLU(\n",
              "                    (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
              "                  )\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                  (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0-1): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 2560, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(2560, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1920, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "          (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(1920, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (upsamplers): ModuleList(\n",
              "        (0): Upsample2D(\n",
              "          (conv): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (2): CrossAttnUpBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-2): 3 x Transformer2DModel(\n",
              "          (norm): GroupNorm(32, 640, eps=1e-06, affine=True)\n",
              "          (proj_in): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (transformer_blocks): ModuleList(\n",
              "            (0): BasicTransformerBlock(\n",
              "              (norm1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn1): Attention(\n",
              "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_k): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_v): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn2): Attention(\n",
              "                (to_q): Linear(in_features=640, out_features=640, bias=False)\n",
              "                (to_k): Linear(in_features=768, out_features=640, bias=False)\n",
              "                (to_v): Linear(in_features=768, out_features=640, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=640, out_features=640, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm3): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
              "              (ff): FeedForward(\n",
              "                (net): ModuleList(\n",
              "                  (0): GEGLU(\n",
              "                    (proj): Linear(in_features=640, out_features=5120, bias=True)\n",
              "                  )\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                  (2): Linear(in_features=2560, out_features=640, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (proj_out): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1920, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1920, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
              "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(1920, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(1280, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
              "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (2): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(960, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=640, bias=True)\n",
              "          (norm2): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (upsamplers): ModuleList(\n",
              "        (0): Upsample2D(\n",
              "          (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (3): CrossAttnUpBlock2D(\n",
              "      (attentions): ModuleList(\n",
              "        (0-2): 3 x Transformer2DModel(\n",
              "          (norm): GroupNorm(32, 320, eps=1e-06, affine=True)\n",
              "          (proj_in): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "          (transformer_blocks): ModuleList(\n",
              "            (0): BasicTransformerBlock(\n",
              "              (norm1): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn1): Attention(\n",
              "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_k): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_v): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm2): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (attn2): Attention(\n",
              "                (to_q): Linear(in_features=320, out_features=320, bias=False)\n",
              "                (to_k): Linear(in_features=768, out_features=320, bias=False)\n",
              "                (to_v): Linear(in_features=768, out_features=320, bias=False)\n",
              "                (to_out): ModuleList(\n",
              "                  (0): Linear(in_features=320, out_features=320, bias=True)\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                )\n",
              "              )\n",
              "              (norm3): LayerNorm((320,), eps=1e-05, elementwise_affine=True)\n",
              "              (ff): FeedForward(\n",
              "                (net): ModuleList(\n",
              "                  (0): GEGLU(\n",
              "                    (proj): Linear(in_features=320, out_features=2560, bias=True)\n",
              "                  )\n",
              "                  (1): Dropout(p=0.0, inplace=False)\n",
              "                  (2): Linear(in_features=1280, out_features=320, bias=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (proj_out): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "      (resnets): ModuleList(\n",
              "        (0): ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 960, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(960, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "        (1-2): 2 x ResnetBlock2D(\n",
              "          (norm1): GroupNorm(32, 640, eps=1e-05, affine=True)\n",
              "          (conv1): Conv2d(640, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (time_emb_proj): Linear(in_features=1280, out_features=320, bias=True)\n",
              "          (norm2): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
              "          (dropout): Dropout(p=0.0, inplace=False)\n",
              "          (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (nonlinearity): SiLU()\n",
              "          (conv_shortcut): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1))\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (mid_block): UNetMidBlock2DCrossAttn(\n",
              "    (attentions): ModuleList(\n",
              "      (0): Transformer2DModel(\n",
              "        (norm): GroupNorm(32, 1280, eps=1e-06, affine=True)\n",
              "        (proj_in): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "        (transformer_blocks): ModuleList(\n",
              "          (0): BasicTransformerBlock(\n",
              "            (norm1): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn1): Attention(\n",
              "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "              (to_k): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "              (to_v): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "              (to_out): ModuleList(\n",
              "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                (1): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (norm2): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (attn2): Attention(\n",
              "              (to_q): Linear(in_features=1280, out_features=1280, bias=False)\n",
              "              (to_k): Linear(in_features=768, out_features=1280, bias=False)\n",
              "              (to_v): Linear(in_features=768, out_features=1280, bias=False)\n",
              "              (to_out): ModuleList(\n",
              "                (0): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "                (1): Dropout(p=0.0, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (norm3): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
              "            (ff): FeedForward(\n",
              "              (net): ModuleList(\n",
              "                (0): GEGLU(\n",
              "                  (proj): Linear(in_features=1280, out_features=10240, bias=True)\n",
              "                )\n",
              "                (1): Dropout(p=0.0, inplace=False)\n",
              "                (2): Linear(in_features=5120, out_features=1280, bias=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (proj_out): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (resnets): ModuleList(\n",
              "      (0-1): 2 x ResnetBlock2D(\n",
              "        (norm1): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "        (conv1): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (time_emb_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
              "        (norm2): GroupNorm(32, 1280, eps=1e-05, affine=True)\n",
              "        (dropout): Dropout(p=0.0, inplace=False)\n",
              "        (conv2): Conv2d(1280, 1280, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (nonlinearity): SiLU()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (conv_norm_out): GroupNorm(32, 320, eps=1e-05, affine=True)\n",
              "  (conv_act): SiLU()\n",
              "  (conv_out): Conv2d(320, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe.unet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn9byKQQWvMs"
      },
      "source": [
        "#LoRa Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_6e933JWsr0"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=4,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"conv1\", \"conv2\", \"conv3\",\"k_proj\", \"v_proj\", \"q_proj\", \"out_proj\", \"fc1\", \"fc2\"],\n",
        "    lora_dropout=0.1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMNf7vPrY5K6"
      },
      "outputs": [],
      "source": [
        "pipe.text_encoder = get_peft_model(pipe.text_encoder, lora_config)\n",
        "pipe.text_encoder = pipe.text_encoder.half()\n",
        "def convert_to_8bit(model):\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, torch.nn.Linear):\n",
        "            input_features = module.in_features\n",
        "            output_features = module.out_features\n",
        "            new_module = bnb.nn.Linear8bitLt(input_features, output_features)\n",
        "            model._modules[name] = new_module\n",
        "        else:\n",
        "            convert_to_8bit(module)\n",
        "\n",
        "convert_to_8bit(pipe.text_encoder)\n",
        "\n",
        "# Print the modified model to verify\n",
        "print(pipe.text_encoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "iJI8MFI0eea4",
        "outputId": "1852d559-63b0-417e-e3f0-48fc4cd44b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.0.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.1.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.2.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.3.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.4.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.5.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.6.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.7.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.8.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.9.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.10.mlp.fc2.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.k_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.k_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.k_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.k_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.k_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.k_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.v_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.q_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.out_proj.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.out_proj.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.out_proj.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.out_proj.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.out_proj.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.self_attn.out_proj.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc1.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc1.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc1.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc1.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc1.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc1.lora_B.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc2.base_layer.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc2.base_layer.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc2.lora_A.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc2.lora_A.default.bias\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc2.lora_B.default.weight\n",
            "Text Encoder Trainable parameter: base_model.model.base_model.model.text_model.encoder.layers.11.mlp.fc2.lora_B.default.bias\n",
            "LoRa model for Text Encoder successfully configured and trainable parameters set.\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    pipe.text_encoder = pipe.text_encoder.cuda()\n",
        "    unet = pipe.unet.cuda()\n",
        "\n",
        "# Print the trainable parameters to verify\n",
        "for name, param in pipe.text_encoder.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(f\"Text Encoder Trainable parameter: {name}\")\n",
        "\n",
        "print(\"LoRa model for Text Encoder successfully configured and trainable parameters set.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8FJqXynMYACF"
      },
      "outputs": [],
      "source": [
        "# Define Custom Dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = self.dataset[idx]\n",
        "        image = item['images']\n",
        "        text = item['text']\n",
        "        return {\n",
        "            'pixel_values': pipe.vae.encode(image.unsqueeze(0)).latent_dist.sample().squeeze(0),\n",
        "            'input_ids': pipe.tokenizer(text, return_tensors=\"pt\").input_ids.squeeze(0)\n",
        "        }\n",
        "\n",
        "train_dataset = CustomDataset(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKY6C5r6YKEL"
      },
      "outputs": [],
      "source": [
        "# Training Arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./stable-diffusion-finetuned\",\n",
        "    per_device_train_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    fp16=True,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        "    gradient_accumulation_steps=4,\n",
        "    logging_steps=100,\n",
        "    remove_unused_columns=False,\n",
        "    optim=\"paged_adamw_8bit\",\n",
        "    push_to_hub=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "collapsed": true,
        "id": "QUOv-fROdQeu",
        "outputId": "0975064c-c905-4ca2-e4b6-13fd93f00af0"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "unsqueeze",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-449dc35b21f8>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1885\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1886\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1887\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2177\u001b[0m             \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2179\u001b[0m                 \u001b[0mtotal_batched_samples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0;31m# We iterate one batch ahead to check when we are at the end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m             \u001b[0mcurrent_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 675\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    676\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-bc4ea480b07f>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         return {\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;34m'pixel_values'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatent_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         }\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image categories\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_animated\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplural\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: unsqueeze"
          ]
        }
      ],
      "source": [
        "class TextToImageTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        pixel_values = inputs['pixel_values']\n",
        "        input_ids = inputs['input_ids']\n",
        "        outputs = model(input_ids=input_ids, pixel_values=pixel_values)\n",
        "        loss = outputs.loss\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Initialize and Start Training\n",
        "trainer = TextToImageTrainer(\n",
        "    model=pipe.text_encoder,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0313b9bf7f1f4704a361b78c9014038e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "044750774be240418376bed2545f3ccd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09272ec727d141a684e3aa2c1c1fa961": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c6e0e169237499e97c2a577c8a853db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d74bfa26af846e6b927daa9cb0910ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cda774e3faf749eb997d7506f41b24fa",
            "placeholder": "​",
            "style": "IPY_MODEL_ff63cde3a2d5437887695f52169550d7",
            "value": "Downloading data: 100%"
          }
        },
        "1029fe4c8a124a29b04c3807a00a635b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18cc15c5bd594449854efbfe85ef2dcf",
            "placeholder": "​",
            "style": "IPY_MODEL_726af3feb27a42429613eff0580f68a7",
            "value": "Token is valid (permission: write)."
          }
        },
        "10fa10b232ee430a8921f8410eccaf9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "177eec2a054a4cd3b830165cc354a145": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c45e77c7a614af18175d7ef018f49a4",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c78bf7ef1fe14abca6d9b9c63cc55199",
            "value": 7
          }
        },
        "18cc15c5bd594449854efbfe85ef2dcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f7e4d9c265400fa37765ee4ae4099a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7b168372fc4422bdf1c1b5a16a03ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1db1bfd49be84fb495bbfb12f6e7613f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeeecaf2be5a4626bde68b507d84340d",
            "max": 360693691,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_364628f805ee47db9e1b351421762df2",
            "value": 360693691
          }
        },
        "29f090164a0d4ada80245b26d050b6a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cbbcfebd52e4c3b8f41ba0a1297943e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cea892d49f74c0bbc584d7f3c42c620": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "302fcdbd038243c6a90ec7a8b94950fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32194941dd784d92acc0a732d226fac7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3315660504f84d1d8a7bf010d06aeb70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332e771354b643faaeab5d344a78bfb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b7d306127724ccba0fa77b720170fd0",
              "IPY_MODEL_90c9c339c660467381b5776ecb9d3372",
              "IPY_MODEL_79a52f309a9940798e82b31210b63d50"
            ],
            "layout": "IPY_MODEL_4be3307b70784bd4a418be01c56bcc8b"
          }
        },
        "35c7b2029dd44d1aa14d43109776232f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc775a698c1b4e35a5bcef4a8c114a70",
            "placeholder": "​",
            "style": "IPY_MODEL_88dad9ccb0e44280b16d1d61bcebfdfb",
            "value": " 361M/361M [00:07&lt;00:00, 60.4MB/s]"
          }
        },
        "364628f805ee47db9e1b351421762df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a2a0bd93881414cbbd093354c5b86ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88aa3f9c7fe7427390258cb328b15963",
            "placeholder": "​",
            "style": "IPY_MODEL_0c6e0e169237499e97c2a577c8a853db",
            "value": " 363M/363M [00:08&lt;00:00, 43.5MB/s]"
          }
        },
        "3f4ac1f2312143cbbf1ab4cf61503a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4191b4a6a06c424c83f83f1a55e32ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43dc950c29c7440692bcdfa744eee9cf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b4359818414a4e8cf6e658112c0d7f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4be3307b70784bd4a418be01c56bcc8b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c45e77c7a614af18175d7ef018f49a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ca1cc19c02d43a4bab16d37316252cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4cca69fefba444b5ad0b965ebf26ad55": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "568f9d64f9444cac884f78838e3b40a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29f090164a0d4ada80245b26d050b6a4",
            "placeholder": "​",
            "style": "IPY_MODEL_4cca69fefba444b5ad0b965ebf26ad55",
            "value": " 361M/361M [00:07&lt;00:00, 58.1MB/s]"
          }
        },
        "58412283b6744e699176ef1dc3dab571": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1029fe4c8a124a29b04c3807a00a635b",
              "IPY_MODEL_5cec24f33a694d4699c3f631a8290624",
              "IPY_MODEL_e10ef5e0a2a44636b2aadbb7d73f5e32",
              "IPY_MODEL_9a8c4b7bf55249fab7eff6027e9f656e"
            ],
            "layout": "IPY_MODEL_efc531666c5c4a9fa75c5ade50415248"
          }
        },
        "58bcbf558bfc4a09b092099e7f277f6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa2baca4ea57447b9f06a62e24ed5f57",
            "placeholder": "​",
            "style": "IPY_MODEL_b6200243d12840659f3002dee4c0ff8e",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "5b7d306127724ccba0fa77b720170fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_98cb0a48c48c43b59efa247a7ffd6f9d",
            "placeholder": "​",
            "style": "IPY_MODEL_2cea892d49f74c0bbc584d7f3c42c620",
            "value": "Downloading readme: 100%"
          }
        },
        "5b9cd79349d44a09a408b8466bdf7849": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cec24f33a694d4699c3f631a8290624": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43dc950c29c7440692bcdfa744eee9cf",
            "placeholder": "​",
            "style": "IPY_MODEL_1d7b168372fc4422bdf1c1b5a16a03ff",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "62f49cfea41f44fcb1f2745bf857cb1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "63d8b161b7ea4b8787aaaf0f7c136653": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "643fbc78a3d2431685d577cfd7f5490b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69dd2ddfc65e44bba698fb435d64063d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09272ec727d141a684e3aa2c1c1fa961",
            "placeholder": "​",
            "style": "IPY_MODEL_fc66f926b32c4d91a85d0eb32732e74e",
            "value": "Downloading data: 100%"
          }
        },
        "704016009fd647f8bc70a22aace71703": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726af3feb27a42429613eff0580f68a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75a1cb04d8fd4864b5405078eeceabf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce6436a5058e4c489758d88ca260855f",
              "IPY_MODEL_881d82ae65a347efaa941c60cf9154d1",
              "IPY_MODEL_d83ede0f158648f691d70a6150af33cd"
            ],
            "layout": "IPY_MODEL_924a3a3a1268445b8f370cbfe6132673"
          }
        },
        "78da4ccaeca349ada0190cf005858f4a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79a52f309a9940798e82b31210b63d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ca1cc19c02d43a4bab16d37316252cc",
            "placeholder": "​",
            "style": "IPY_MODEL_c8f8534da6604a6caf2857ef4cde3535",
            "value": " 836/836 [00:00&lt;00:00, 57.7kB/s]"
          }
        },
        "7be81ad13f2e40079949be1e2fefeb76": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4191b4a6a06c424c83f83f1a55e32ee3",
            "placeholder": "​",
            "style": "IPY_MODEL_5b9cd79349d44a09a408b8466bdf7849",
            "value": "Downloading data: 100%"
          }
        },
        "87aa915f8fae48f69715c37a417c1e83": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_044750774be240418376bed2545f3ccd",
            "placeholder": "​",
            "style": "IPY_MODEL_eb6b193bb2074846ac8d62930e5bdc07",
            "value": "Downloading data: 100%"
          }
        },
        "881d82ae65a347efaa941c60cf9154d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32194941dd784d92acc0a732d226fac7",
            "max": 40658,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec8932bfcc964c358cb4b4372ff89ccd",
            "value": 40658
          }
        },
        "88aa3f9c7fe7427390258cb328b15963": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88dad9ccb0e44280b16d1d61bcebfdfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88fa1d35b4294d2db9a2640373527c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e2d967fba8442fda3e591572aaa51bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90c9c339c660467381b5776ecb9d3372": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5cdb76dbb0b4651a389ad7096e2dc7a",
            "max": 836,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_62f49cfea41f44fcb1f2745bf857cb1f",
            "value": 836
          }
        },
        "924a3a3a1268445b8f370cbfe6132673": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961441061dcb4777a764e2c5ba471c24": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98cb0a48c48c43b59efa247a7ffd6f9d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a8c4b7bf55249fab7eff6027e9f656e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_961441061dcb4777a764e2c5ba471c24",
            "placeholder": "​",
            "style": "IPY_MODEL_643fbc78a3d2431685d577cfd7f5490b",
            "value": "Login successful"
          }
        },
        "9bf64c49d20c4218a4d099a239f1f980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7be81ad13f2e40079949be1e2fefeb76",
              "IPY_MODEL_ffb755f925914e409181eaf878178a2e",
              "IPY_MODEL_568f9d64f9444cac884f78838e3b40a4"
            ],
            "layout": "IPY_MODEL_18f7e4d9c265400fa37765ee4ae4099a"
          }
        },
        "a30bea78cff54db2af3846ebc456f3e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0d74bfa26af846e6b927daa9cb0910ba",
              "IPY_MODEL_1db1bfd49be84fb495bbfb12f6e7613f",
              "IPY_MODEL_35c7b2029dd44d1aa14d43109776232f"
            ],
            "layout": "IPY_MODEL_3f4ac1f2312143cbbf1ab4cf61503a0c"
          }
        },
        "a5cdb76dbb0b4651a389ad7096e2dc7a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa2baca4ea57447b9f06a62e24ed5f57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6200243d12840659f3002dee4c0ff8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b011fd3010464688f1854f4054ec64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc775a698c1b4e35a5bcef4a8c114a70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c78bf7ef1fe14abca6d9b9c63cc55199": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8f8534da6604a6caf2857ef4cde3535": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cda774e3faf749eb997d7506f41b24fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce6436a5058e4c489758d88ca260855f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49b4359818414a4e8cf6e658112c0d7f",
            "placeholder": "​",
            "style": "IPY_MODEL_704016009fd647f8bc70a22aace71703",
            "value": "Generating train split: 100%"
          }
        },
        "cf952a6f8b7e46199b57f1502b505670": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3315660504f84d1d8a7bf010d06aeb70",
            "placeholder": "​",
            "style": "IPY_MODEL_10fa10b232ee430a8921f8410eccaf9b",
            "value": " 364M/364M [00:11&lt;00:00, 42.5MB/s]"
          }
        },
        "d144318d066e49a2bb9a2ce99642d4ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4bb4ceaca3f4f87942e51745819a82c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54c47f31de04ff6b84aeeabe8be47ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d83ede0f158648f691d70a6150af33cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4bb4ceaca3f4f87942e51745819a82c",
            "placeholder": "​",
            "style": "IPY_MODEL_e9e7be631911449d93074654bae1be53",
            "value": " 40658/40658 [00:08&lt;00:00, 4950.67 examples/s]"
          }
        },
        "ddeadbee7bd543d18b0083c89b06be43": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_87aa915f8fae48f69715c37a417c1e83",
              "IPY_MODEL_e7b94460c7554552a00e430b41c832fa",
              "IPY_MODEL_cf952a6f8b7e46199b57f1502b505670"
            ],
            "layout": "IPY_MODEL_63d8b161b7ea4b8787aaaf0f7c136653"
          }
        },
        "e10ef5e0a2a44636b2aadbb7d73f5e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_302fcdbd038243c6a90ec7a8b94950fe",
            "placeholder": "​",
            "style": "IPY_MODEL_2cbbcfebd52e4c3b8f41ba0a1297943e",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "e717354177344a5ab7157f492bf31764": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa54c34c801242beaa7d73e1399d54d3",
            "placeholder": "​",
            "style": "IPY_MODEL_d54c47f31de04ff6b84aeeabe8be47ab",
            "value": " 7/7 [00:22&lt;00:00,  3.55s/it]"
          }
        },
        "e7b94460c7554552a00e430b41c832fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78da4ccaeca349ada0190cf005858f4a",
            "max": 364001799,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e8b881ca928d4b1596431fbc2726450b",
            "value": 364001799
          }
        },
        "e8b881ca928d4b1596431fbc2726450b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9be71ec6215422fba8f7454f865e074": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69dd2ddfc65e44bba698fb435d64063d",
              "IPY_MODEL_f6d30505e82f4c5e8a2d486650da8888",
              "IPY_MODEL_3a2a0bd93881414cbbd093354c5b86ef"
            ],
            "layout": "IPY_MODEL_fbf1eda74a214234b24eb447ce45fd2a"
          }
        },
        "e9e7be631911449d93074654bae1be53": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb6b193bb2074846ac8d62930e5bdc07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec8932bfcc964c358cb4b4372ff89ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eeeecaf2be5a4626bde68b507d84340d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efc531666c5c4a9fa75c5ade50415248": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "f6d30505e82f4c5e8a2d486650da8888": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0313b9bf7f1f4704a361b78c9014038e",
            "max": 363307975,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d144318d066e49a2bb9a2ce99642d4ec",
            "value": 363307975
          }
        },
        "fa54c34c801242beaa7d73e1399d54d3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb297017829a4dca969c53460dfc8c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58bcbf558bfc4a09b092099e7f277f6b",
              "IPY_MODEL_177eec2a054a4cd3b830165cc354a145",
              "IPY_MODEL_e717354177344a5ab7157f492bf31764"
            ],
            "layout": "IPY_MODEL_8e2d967fba8442fda3e591572aaa51bc"
          }
        },
        "fbf1eda74a214234b24eb447ce45fd2a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc66f926b32c4d91a85d0eb32732e74e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff63cde3a2d5437887695f52169550d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffb755f925914e409181eaf878178a2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6b011fd3010464688f1854f4054ec64",
            "max": 361377153,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88fa1d35b4294d2db9a2640373527c8d",
            "value": 361377153
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}